{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play w w/o embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T11:46:27.826994Z",
     "start_time": "2018-10-20T11:46:27.655000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n",
      "CUDA: True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%env CUDA_VISIBLE_DEVICES=2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from IPython.core.debugger import set_trace\n",
    "from pytorch.encoder_decoder import (make_model,\n",
    "                                     SimpleLossCompute)\n",
    "\n",
    "# we will use CUDA if it is available\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE=torch.device('cuda:0') # or set to 'cpu'\n",
    "print(\"CUDA:\", USE_CUDA)\n",
    "print(DEVICE)\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T11:31:52.507088Z",
     "start_time": "2018-10-20T11:31:52.499437Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"\"\"Object for holding a batch of data with mask during training.\n",
    "    Input is a batch from a torch text iterator.\n",
    "    \"\"\"\n",
    "    def __init__(self, src, trg, pad_index=0):\n",
    "        \n",
    "        src, src_lengths = src\n",
    "        \n",
    "        self.src = src\n",
    "        self.src_lengths = src_lengths\n",
    "        self.src_mask = (src != pad_index).unsqueeze(-2)\n",
    "        self.nseqs = src.size(0)\n",
    "        \n",
    "        self.trg = None\n",
    "        self.trg_y = None\n",
    "        self.trg_mask = None\n",
    "        self.trg_lengths = None\n",
    "        self.ntokens = None\n",
    "\n",
    "        if trg is not None:\n",
    "            trg, trg_lengths = trg\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_lengths = trg_lengths\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = (self.trg_y != pad_index)\n",
    "            self.ntokens = (self.trg_y != pad_index).data.sum().item()\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            self.src = self.src.cuda()\n",
    "            self.src_mask = self.src_mask.cuda()\n",
    "\n",
    "            if trg is not None:\n",
    "                self.trg = self.trg.cuda()\n",
    "                self.trg_y = self.trg_y.cuda()\n",
    "                self.trg_mask = self.trg_mask.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T11:34:04.483287Z",
     "start_time": "2018-10-20T11:34:04.478338Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def data_gen(num_words=11, batch_size=16, num_batches=100, length=10, pad_index=0, sos_index=1):\n",
    "    \"\"\"Generate random data for a src-tgt copy task.\"\"\"\n",
    "    for i in range(num_batches):\n",
    "        data = torch.from_numpy(\n",
    "          np.random.randint(1, num_words, size=(batch_size, length)))\n",
    "        data[:, 0] = sos_index\n",
    "        data = data.cuda() if USE_CUDA else data\n",
    "        src = data[:, 1:]\n",
    "        trg = data\n",
    "        src_lengths = [length-1] * batch_size\n",
    "        trg_lengths = [length] * batch_size\n",
    "        yield Batch((src, src_lengths), (trg, trg_lengths), pad_index=pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T11:34:05.460966Z",
     "start_time": "2018-10-20T11:34:05.453022Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train_copy_task(emb_size):\n",
    "    \"\"\"Train the simple copy task.\"\"\"\n",
    "    num_words = 11\n",
    "    # criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=0)\n",
    "    criterion = nn.NLLLoss(size_average=False, ignore_index=0)\n",
    "    model = make_model(num_words,\n",
    "                       num_words,\n",
    "                       device=DEVICE,\n",
    "                       emb_size=emb_size,\n",
    "                       hidden_size=64)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "    eval_data = list(data_gen(num_words=num_words, batch_size=1, num_batches=100))\n",
    " \n",
    "    dev_perplexities = []\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        model.cuda()\n",
    "\n",
    "    for epoch in range(10):\n",
    "        \n",
    "        print(\"Epoch %d\" % epoch)\n",
    "\n",
    "        # train\n",
    "        model.train()\n",
    "        data = data_gen(num_words=num_words, batch_size=32, num_batches=100)\n",
    "        run_epoch(data, model,\n",
    "                  SimpleLossCompute(model.generator, criterion, optim))\n",
    "\n",
    "        # evaluate\n",
    "        model.eval()\n",
    "        with torch.no_grad(): \n",
    "            perplexity = run_epoch(eval_data, model,\n",
    "                                   SimpleLossCompute(model.generator, criterion, None))\n",
    "            print(\"Evaluation perplexity: %f\" % perplexity)\n",
    "            dev_perplexities.append(perplexity)\n",
    "            print_examples(eval_data, model, n=2, max_len=9)\n",
    "        \n",
    "    return dev_perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:03:06.336179Z",
     "start_time": "2018-10-19T12:02:36.151617Z"
    },
    "code_folding": [
     0,
     4
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch Step: 50 Loss: 20.044893 Tokens per Sec: 11938.392983\n",
      "Epoch Step: 100 Loss: 17.905952 Tokens per Sec: 11944.160682\n",
      "Evaluation perplexity: 7.241447\n",
      "\n",
      "Example #1\n",
      "Src :  9 9 1 6 10 9 2 2 3\n",
      "Trg :  9 9 1 6 10 9 2 2 3\n",
      "Pred:  9 9 9 9 9 9 9 9 9\n",
      "\n",
      "Example #2\n",
      "Src :  5 6 6 3 6 6 8 2 3\n",
      "Trg :  5 6 6 3 6 6 8 2 3\n",
      "Pred:  6 6 6 6 6 6 6 6 6\n",
      "\n",
      "Epoch 1\n",
      "Epoch Step: 50 Loss: 16.122639 Tokens per Sec: 12901.691289\n",
      "Epoch Step: 100 Loss: 12.517569 Tokens per Sec: 13032.871902\n",
      "Evaluation perplexity: 3.824094\n",
      "\n",
      "Example #1\n",
      "Src :  9 9 1 6 10 9 2 2 3\n",
      "Trg :  9 9 1 6 10 9 2 2 3\n",
      "Pred:  9 9 10 2 6 9 2 2 9\n",
      "\n",
      "Example #2\n",
      "Src :  5 6 6 3 6 6 8 2 3\n",
      "Trg :  5 6 6 3 6 6 8 2 3\n",
      "Pred:  6 6 5 6 3 8 6 3 6\n",
      "\n",
      "Epoch 2\n",
      "Epoch Step: 50 Loss: 8.160336 Tokens per Sec: 12866.917026\n",
      "Epoch Step: 100 Loss: 4.422697 Tokens per Sec: 12832.043450\n",
      "Evaluation perplexity: 1.618500\n",
      "\n",
      "Example #1\n",
      "Src :  9 9 1 6 10 9 2 2 3\n",
      "Trg :  9 9 1 6 10 9 2 2 3\n",
      "Pred:  9 9 6 1 9 10 2 2 3\n",
      "\n",
      "Example #2\n",
      "Src :  5 6 6 3 6 6 8 2 3\n",
      "Trg :  5 6 6 3 6 6 8 2 3\n",
      "Pred:  6 5 6 6 3 2 8 6 3\n",
      "\n",
      "Epoch 3\n",
      "Epoch Step: 50 Loss: 2.221241 Tokens per Sec: 12492.872226\n",
      "Epoch Step: 100 Loss: 1.258339 Tokens per Sec: 12504.407765\n",
      "Evaluation perplexity: 1.140487\n",
      "\n",
      "Example #1\n",
      "Src :  9 9 1 6 10 9 2 2 3\n",
      "Trg :  9 9 1 6 10 9 2 2 3\n",
      "Pred:  9 9 1 6 10 9 2 2 3\n",
      "\n",
      "Example #2\n",
      "Src :  5 6 6 3 6 6 8 2 3\n",
      "Trg :  5 6 6 3 6 6 8 2 3\n",
      "Pred:  5 6 6 3 6 6 8 2 3\n",
      "\n",
      "Epoch 4\n",
      "Epoch Step: 50 Loss: 0.791215 Tokens per Sec: 13863.227247\n",
      "Epoch Step: 100 Loss: 0.607102 Tokens per Sec: 12763.855608\n",
      "Evaluation perplexity: 1.051206\n",
      "\n",
      "Example #1\n",
      "Src :  9 9 1 6 10 9 2 2 3\n",
      "Trg :  9 9 1 6 10 9 2 2 3\n",
      "Pred:  9 9 1 6 10 9 2 2 3\n",
      "\n",
      "Example #2\n",
      "Src :  5 6 6 3 6 6 8 2 3\n",
      "Trg :  5 6 6 3 6 6 8 2 3\n",
      "Pred:  5 6 6 3 6 6 8 2 3\n",
      "\n",
      "Epoch 5\n",
      "Epoch Step: 50 Loss: 0.398093 Tokens per Sec: 15095.554460\n",
      "Epoch Step: 100 Loss: 0.282328 Tokens per Sec: 13783.154869\n",
      "Evaluation perplexity: 1.021497\n",
      "\n",
      "Example #1\n",
      "Src :  9 9 1 6 10 9 2 2 3\n",
      "Trg :  9 9 1 6 10 9 2 2 3\n",
      "Pred:  9 9 1 6 10 9 2 2 3\n",
      "\n",
      "Example #2\n",
      "Src :  5 6 6 3 6 6 8 2 3\n",
      "Trg :  5 6 6 3 6 6 8 2 3\n",
      "Pred:  5 6 6 3 6 6 8 2 3\n",
      "\n",
      "Epoch 6\n",
      "Epoch Step: 50 Loss: 0.198663 Tokens per Sec: 12595.281616\n",
      "Epoch Step: 100 Loss: 0.152758 Tokens per Sec: 12735.370302\n",
      "Evaluation perplexity: 1.012405\n",
      "\n",
      "Example #1\n",
      "Src :  9 9 1 6 10 9 2 2 3\n",
      "Trg :  9 9 1 6 10 9 2 2 3\n",
      "Pred:  9 9 1 6 10 9 2 2 3\n",
      "\n",
      "Example #2\n",
      "Src :  5 6 6 3 6 6 8 2 3\n",
      "Trg :  5 6 6 3 6 6 8 2 3\n",
      "Pred:  5 6 6 3 6 6 8 2 3\n",
      "\n",
      "Epoch 7\n",
      "Epoch Step: 50 Loss: 0.136781 Tokens per Sec: 12700.590913\n",
      "Epoch Step: 100 Loss: 0.084141 Tokens per Sec: 12299.365503\n",
      "Evaluation perplexity: 1.007584\n",
      "\n",
      "Example #1\n",
      "Src :  9 9 1 6 10 9 2 2 3\n",
      "Trg :  9 9 1 6 10 9 2 2 3\n",
      "Pred:  9 9 1 6 10 9 2 2 3\n",
      "\n",
      "Example #2\n",
      "Src :  5 6 6 3 6 6 8 2 3\n",
      "Trg :  5 6 6 3 6 6 8 2 3\n",
      "Pred:  5 6 6 3 6 6 8 2 3\n",
      "\n",
      "Epoch 8\n",
      "Epoch Step: 50 Loss: 0.069798 Tokens per Sec: 12371.617658\n",
      "Epoch Step: 100 Loss: 0.062122 Tokens per Sec: 11945.937207\n",
      "Evaluation perplexity: 1.005499\n",
      "\n",
      "Example #1\n",
      "Src :  9 9 1 6 10 9 2 2 3\n",
      "Trg :  9 9 1 6 10 9 2 2 3\n",
      "Pred:  9 9 1 6 10 9 2 2 3\n",
      "\n",
      "Example #2\n",
      "Src :  5 6 6 3 6 6 8 2 3\n",
      "Trg :  5 6 6 3 6 6 8 2 3\n",
      "Pred:  5 6 6 3 6 6 8 2 3\n",
      "\n",
      "Epoch 9\n",
      "Epoch Step: 50 Loss: 0.057026 Tokens per Sec: 12674.753794\n",
      "Epoch Step: 100 Loss: 0.046384 Tokens per Sec: 12556.107327\n",
      "Evaluation perplexity: 1.003745\n",
      "\n",
      "Example #1\n",
      "Src :  9 9 1 6 10 9 2 2 3\n",
      "Trg :  9 9 1 6 10 9 2 2 3\n",
      "Pred:  9 9 1 6 10 9 2 2 3\n",
      "\n",
      "Example #2\n",
      "Src :  5 6 6 3 6 6 8 2 3\n",
      "Trg :  5 6 6 3 6 6 8 2 3\n",
      "Pred:  5 6 6 3 6 6 8 2 3\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the copy task\n",
    "# try embedding size = 1\n",
    "dev_perplexities = train_copy_task(emb_size=32)\n",
    "\n",
    "def plot_perplexity(perplexities):\n",
    "    \"\"\"plot perplexities\"\"\"\n",
    "    plt.title(\"Perplexity per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Perplexity\")\n",
    "    plt.plot(perplexities)\n",
    "    \n",
    "plot_perplexity(dev_perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:02:16.917188Z",
     "start_time": "2018-10-19T12:01:40.689667Z"
    },
    "code_folding": [
     4
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch Step: 50 Loss: 20.620859 Tokens per Sec: 13144.345327\n",
      "Epoch Step: 100 Loss: 20.235697 Tokens per Sec: 13655.166913\n",
      "Evaluation perplexity: 9.289641\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  10 10 10 10 10 10 10 10 10\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  6 6 6 6 6 6 6 6 6\n",
      "\n",
      "Epoch 1\n",
      "Epoch Step: 50 Loss: 19.976292 Tokens per Sec: 13774.029839\n",
      "Epoch Step: 100 Loss: 19.776014 Tokens per Sec: 12919.903457\n",
      "Evaluation perplexity: 8.729949\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  3 3 3 9 9 9 9 9 9\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  3 3 4 6 6 6 6 6 6\n",
      "\n",
      "Epoch 2\n",
      "Epoch Step: 50 Loss: 19.390150 Tokens per Sec: 12943.363090\n",
      "Epoch Step: 100 Loss: 18.283533 Tokens per Sec: 12725.037413\n",
      "Evaluation perplexity: 7.795435\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  8 2 2 2 10 10 10 5 5\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  3 9 8 2 1 1 1 1 1\n",
      "\n",
      "Epoch 3\n",
      "Epoch Step: 50 Loss: 17.463692 Tokens per Sec: 11781.925180\n",
      "Epoch Step: 100 Loss: 16.548504 Tokens per Sec: 12497.132205\n",
      "Evaluation perplexity: 5.890461\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  10 4 6 7 3 3 4 5 7\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  7 3 4 6 6 7 7 6 6\n",
      "\n",
      "Epoch 4\n",
      "Epoch Step: 50 Loss: 14.209116 Tokens per Sec: 11668.479965\n",
      "Epoch Step: 100 Loss: 11.093970 Tokens per Sec: 14062.442034\n",
      "Evaluation perplexity: 3.389456\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  4 4 5 7 9 3 7 8 2\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  4 7 3 6 5 5 4 6 6\n",
      "\n",
      "Epoch 5\n",
      "Epoch Step: 50 Loss: 9.251182 Tokens per Sec: 13358.950111\n",
      "Epoch Step: 100 Loss: 7.747298 Tokens per Sec: 12623.161476\n",
      "Evaluation perplexity: 2.382614\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  4 8 5 7 10 3 7 8 5\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  8 8 3 6 5 5 4 6 5\n",
      "\n",
      "Epoch 6\n",
      "Epoch Step: 50 Loss: 6.988616 Tokens per Sec: 12291.933759\n",
      "Epoch Step: 100 Loss: 6.282692 Tokens per Sec: 13054.418561\n",
      "Evaluation perplexity: 1.935422\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  4 8 5 7 9 3 7 8 5\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  8 8 3 6 2 2 8 6 2\n",
      "\n",
      "Epoch 7\n",
      "Epoch Step: 50 Loss: 5.516691 Tokens per Sec: 14813.533941\n",
      "Epoch Step: 100 Loss: 4.729788 Tokens per Sec: 11964.940283\n",
      "Evaluation perplexity: 1.681443\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  4 8 5 7 9 3 7 8 5\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  8 8 3 6 5 2 8 6 2\n",
      "\n",
      "Epoch 8\n",
      "Epoch Step: 50 Loss: 4.333264 Tokens per Sec: 12952.714703\n",
      "Epoch Step: 100 Loss: 3.840941 Tokens per Sec: 12198.511489\n",
      "Evaluation perplexity: 1.496213\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  4 8 5 7 9 3 7 8 5\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  8 8 3 6 5 2 8 6 2\n",
      "\n",
      "Epoch 9\n",
      "Epoch Step: 50 Loss: 3.226867 Tokens per Sec: 12729.213089\n",
      "Epoch Step: 100 Loss: 2.831897 Tokens per Sec: 11531.514182\n",
      "Evaluation perplexity: 1.338933\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  4 8 5 7 10 3 7 8 5\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  8 8 3 6 5 2 8 6 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the copy task\n",
    "# try embedding size = 1\n",
    "dev_perplexities = train_copy_task(emb_size=1)\n",
    "\n",
    "def plot_perplexity(perplexities):\n",
    "    \"\"\"plot perplexities\"\"\"\n",
    "    plt.title(\"Perplexity per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Perplexity\")\n",
    "    plt.plot(perplexities)\n",
    "    \n",
    "plot_perplexity(dev_perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T04:52:12.072648Z",
     "start_time": "2018-10-19T04:51:41.666129Z"
    },
    "code_folding": [
     3
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch Step: 50 Loss: 19.715988 Tokens per Sec: 15243.757510\n",
      "Epoch Step: 100 Loss: 17.732924 Tokens per Sec: 14671.975055\n",
      "Evaluation perplexity: 7.076631\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  7 7 5 7 5 7 5 7 5\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  6 6 6 8 6 6 6 3 6\n",
      "\n",
      "Epoch 1\n",
      "Epoch Step: 50 Loss: 15.542068 Tokens per Sec: 16073.500298\n",
      "Epoch Step: 100 Loss: 11.795482 Tokens per Sec: 14953.629224\n",
      "Evaluation perplexity: 3.499979\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  4 8 7 8 7 8 3 8 7\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  8 8 6 2 8 6 8 2 6\n",
      "\n",
      "Epoch 2\n",
      "Epoch Step: 50 Loss: 7.732324 Tokens per Sec: 15271.867974\n",
      "Epoch Step: 100 Loss: 5.230344 Tokens per Sec: 17670.540350\n",
      "Evaluation perplexity: 1.730301\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  4 8 5 7 10 8 7 3 5\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  8 8 3 6 5 2 8 2 6\n",
      "\n",
      "Epoch 3\n",
      "Epoch Step: 50 Loss: 3.126701 Tokens per Sec: 16351.969409\n",
      "Epoch Step: 100 Loss: 2.028455 Tokens per Sec: 15553.701364\n",
      "Evaluation perplexity: 1.219677\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  4 8 5 7 10 3 7 8 5\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  8 8 3 6 5 2 8 6 2\n",
      "\n",
      "Epoch 4\n",
      "Epoch Step: 50 Loss: 1.280095 Tokens per Sec: 14541.514670\n",
      "Epoch Step: 100 Loss: 0.877995 Tokens per Sec: 14363.217897\n",
      "Evaluation perplexity: 1.082045\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  4 8 5 7 10 3 7 8 5\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  8 8 3 6 5 2 8 6 2\n",
      "\n",
      "Epoch 5\n",
      "Epoch Step: 50 Loss: 0.568253 Tokens per Sec: 14894.438936\n",
      "Epoch Step: 100 Loss: 0.496342 Tokens per Sec: 13188.439989\n",
      "Evaluation perplexity: 1.039292\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  4 8 5 7 10 3 7 8 5\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  8 8 3 6 5 2 8 6 2\n",
      "\n",
      "Epoch 6\n",
      "Epoch Step: 50 Loss: 0.381517 Tokens per Sec: 14369.221809\n",
      "Epoch Step: 100 Loss: 0.256878 Tokens per Sec: 15648.109288\n",
      "Evaluation perplexity: 1.020609\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  4 8 5 7 10 3 7 8 5\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  8 8 3 6 5 2 8 6 2\n",
      "\n",
      "Epoch 7\n",
      "Epoch Step: 50 Loss: 0.276753 Tokens per Sec: 16270.634320\n",
      "Epoch Step: 100 Loss: 0.181054 Tokens per Sec: 14346.364084\n",
      "Evaluation perplexity: 1.013404\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  4 8 5 7 10 3 7 8 5\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  8 8 3 6 5 2 8 6 2\n",
      "\n",
      "Epoch 8\n",
      "Epoch Step: 50 Loss: 0.133048 Tokens per Sec: 16124.784811\n",
      "Epoch Step: 100 Loss: 0.115816 Tokens per Sec: 14301.936201\n",
      "Evaluation perplexity: 1.010167\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  4 8 5 7 10 3 7 8 5\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  8 8 3 6 5 2 8 6 2\n",
      "\n",
      "Epoch 9\n",
      "Epoch Step: 50 Loss: 0.121158 Tokens per Sec: 14751.214537\n",
      "Epoch Step: 100 Loss: 0.126507 Tokens per Sec: 14148.370212\n",
      "Evaluation perplexity: 1.006191\n",
      "\n",
      "Example #1\n",
      "Src :  4 8 5 7 10 3 7 8 5\n",
      "Trg :  4 8 5 7 10 3 7 8 5\n",
      "Pred:  4 8 5 7 10 3 7 8 5\n",
      "\n",
      "Example #2\n",
      "Src :  8 8 3 6 5 2 8 6 2\n",
      "Trg :  8 8 3 6 5 2 8 6 2\n",
      "Pred:  8 8 3 6 5 2 8 6 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the copy task\n",
    "dev_perplexities = train_copy_task()\n",
    "\n",
    "def plot_perplexity(perplexities):\n",
    "    \"\"\"plot perplexities\"\"\"\n",
    "    plt.title(\"Perplexity per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Perplexity\")\n",
    "    plt.plot(perplexities)\n",
    "    \n",
    "plot_perplexity(dev_perplexities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Mimic the dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T04:58:39.431253Z",
     "start_time": "2018-10-19T04:57:39.441302Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+git://github.com/pytorch/text\n",
      "  Cloning git://github.com/pytorch/text to /tmp/pip-req-build-zuwqmp5n\n",
      "Collecting spacy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/39/288640f591b29aac6996c97ddfafc3262ae0be7513e06bc560921b112d7c/spacy-2.0.16-cp36-cp36m-manylinux1_x86_64.whl (23.3MB)\n",
      "\u001b[K    100% |################################| 23.3MB 696kB/s eta 0:00:01  0% |                                | 215kB 2.7MB/s eta 0:00:09\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from torchtext==0.4.0) (4.23.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from torchtext==0.4.0) (2.14.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from torchtext==0.4.0) (0.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torchtext==0.4.0) (1.14.5)\n",
      "Collecting msgpack-numpy<0.4.4 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/45/464be6da85b5ca893cfcbd5de3b31a6710f636ccb8521b17bd4110a08d94/msgpack_numpy-0.4.3.2-py2.py3-none-any.whl\n",
      "Collecting plac<1.0.0,>=0.9.6 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
      "Collecting dill<0.3,>=0.2 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/78/8b96476f4ae426db71c6e86a8e6a81407f015b34547e442291cd397b18f3/dill-0.2.8.2.tar.gz (150kB)\n",
      "\u001b[K    100% |################################| 153kB 27.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/38/40/6b39438f7eefbb46460f645b8eefebc0c5f1cd38a934a2189c39d8bd0225/murmurhash-1.0.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting preshed<2.1.0,>=2.0.1 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83kB)\n",
      "\u001b[K    100% |################################| 92kB 23.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/3d/61/9b0520c28eb199a4b1ca667d96dd625bba003c14c75230195f9691975f85/cymem-2.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting regex==2018.01.10 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/f4/7146c3812f96fcaaf2d06ff6862582302626a59011ccb6f2833bb38d80f7/regex-2018.01.10.tar.gz (612kB)\n",
      "\u001b[K    100% |################################| 614kB 21.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting ujson>=1.35 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\n",
      "\u001b[K    100% |################################| 194kB 20.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting thinc<6.13.0,>=6.12.0 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/18/e320bfc57c20df39cc5ffa1915c7b5402a9038f290ddd85b5b72689bd57a/thinc-6.12.0-cp36-cp36m-manylinux1_x86_64.whl (1.9MB)\n",
      "\u001b[K    100% |################################| 1.9MB 12.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting msgpack>=0.3.0 (from msgpack-numpy<0.4.4->spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/4e/dcf124fd97e5f5611123d6ad9f40ffd6eb979d1efdc1049e28a795672fcd/msgpack-0.5.6-cp36-cp36m-manylinux1_x86_64.whl (315kB)\n",
      "\u001b[K    100% |################################| 317kB 18.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting wrapt<1.11.0,>=1.10.0 (from thinc<6.13.0,>=6.12.0->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/47/66897906448185fcb77fc3c2b1bc20ed0ecca81a0f2f88eda3fc5a34fc3d/wrapt-1.10.11.tar.gz\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.0->spacy) (1.11.0)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /opt/conda/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.0->spacy) (0.9.0.1)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /opt/conda/lib/python3.6/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.0->spacy) (0.9.0)\n",
      "Building wheels for collected packages: torchtext, dill, regex, ujson, wrapt\n",
      "  Running setup.py bdist_wheel for torchtext ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-pplwnwc5/wheels/39/42/ff/82f5ccbb0f30b25e14610376f5d0c67913fc05017dab59f8eb\n",
      "  Running setup.py bdist_wheel for dill ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/keras/.cache/pip/wheels/e2/5d/17/f87cb7751896ac629b435a8696f83ee75b11029f5d6f6bda72\n",
      "  Running setup.py bdist_wheel for regex ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/keras/.cache/pip/wheels/74/17/3f/c77bba99efd74ba1a19862c9dd97f4b6d735e2826721dc00ff\n",
      "  Running setup.py bdist_wheel for ujson ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/keras/.cache/pip/wheels/28/77/e4/0311145b9c2e2f01470e744855131f9e34d6919687550f87d1\n",
      "  Running setup.py bdist_wheel for wrapt ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/keras/.cache/pip/wheels/48/5d/04/22361a593e70d23b1f7746d932802efe1f0e523376a74f321e\n",
      "Successfully built torchtext dill regex ujson wrapt\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-fft 1.0.0 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorboard 1.8.0 has requirement bleach==1.5.0, but you'll have bleach 2.1.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorboard 1.8.0 has requirement html5lib==0.9999999, but you'll have html5lib 1.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mkaggle-cli 0.12.13 has requirement lxml<4.1,>=4.0.0, but you'll have lxml 4.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mspacy 2.0.16 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
      "Installing collected packages: msgpack, msgpack-numpy, plac, dill, murmurhash, cymem, preshed, regex, ujson, wrapt, thinc, spacy, torchtext\n",
      "Successfully installed cymem-2.0.2 dill-0.2.8.2 msgpack-0.5.6 msgpack-numpy-0.4.3.2 murmurhash-1.0.1 plac-0.9.6 preshed-2.0.1 regex-2018.1.10 spacy-2.0.16 thinc-6.12.0 torchtext-0.4.0 ujson-1.35 wrapt-1.10.11\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+git://github.com/pytorch/text spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T04:59:34.033301Z",
     "start_time": "2018-10-19T04:59:15.218892Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
      "\u001b[K    100% |################################| 37.4MB 10.0MB/s a 0:00:0111 3% |#                               | 1.2MB 51.1MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "  Running setup.py install for en-core-web-sm ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed en-core-web-sm-2.0.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /opt/conda/lib/python3.6/site-packages/en_core_web_sm -->\n",
      "    /opt/conda/lib/python3.6/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n",
      "Collecting de_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.0.0/de_core_news_sm-2.0.0.tar.gz#egg=de_core_news_sm==2.0.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.0.0/de_core_news_sm-2.0.0.tar.gz (38.2MB)\n",
      "\u001b[K    100% |################################| 38.2MB 96.9MB/s eta 0:00:01 1% |                                | 450kB 840kB/s eta 0:00:45    13% |####                            | 5.3MB 27.8MB/s eta 0:00:02    63% |####################            | 24.2MB 62.5MB/s eta 0:00:01    82% |##########################      | 31.3MB 83.3MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: de-core-news-sm\n",
      "  Running setup.py install for de-core-news-sm ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed de-core-news-sm-2.0.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /opt/conda/lib/python3.6/site-packages/de_core_news_sm -->\n",
      "    /opt/conda/lib/python3.6/site-packages/spacy/data/de\n",
      "\n",
      "    You can now load the model via spacy.load('de')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en\n",
    "!python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def score_task1(df_true, df_pred):\n",
    "    df_true = df_true.set_index('id')\n",
    "    df_pred = df_pred.set_index('id')\n",
    "    df_pred = df_pred.loc[df_true.index]\n",
    "    return f1_score(df_true.target, df_pred.target, average='macro')\n",
    "\n",
    "\n",
    "def score_task2(df_true, df_pred):\n",
    "    df_true = df_true.set_index('id')\n",
    "    df_pred = df_pred.set_index('id')\n",
    "    df_pred = df_pred.loc[df_true.index]\n",
    "\n",
    "    # false correction if no target == 1\n",
    "    df_pred.loc[df_pred.target != 1] = ''\n",
    "    return np.mean(df_true.loc[df_true.target == 1, 'fullname_true']\n",
    "                   == df_pred.loc[df_true.target == 1, 'fullname_true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T11:37:40.375913Z",
     "start_time": "2018-10-20T11:36:49.942892Z"
    },
    "code_folding": [
     35,
     42
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from torchtext import data, datasets\n",
    "\n",
    "\"\"\"\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "cns = train_df.country.value_counts()\n",
    "top_countries = list(cns[cns>100].index)\n",
    "        \n",
    "train_df['country'] = train_df['country'].apply(lambda x: x if x in top_countries else 'OTHER')\n",
    "train_df.loc[pd.isnull(train_df.fullname_true),\n",
    "             'fullname_true'] = train_df.loc[pd.isnull(train_df.fullname_true),\n",
    "                                             'fullname']\n",
    "\n",
    "test_df['country'] = test_df['country'].apply(lambda x: x if x in top_countries else 'OTHER')\n",
    "\n",
    "cn_dict = dict(zip(sorted(list(train_df['country'].unique())),\n",
    "                   range(train_df['country'].nunique())))\n",
    "\n",
    "train_df['country'] = train_df['country'].apply(lambda x: cn_dict[x])\n",
    "test_df['country'] = test_df['country'].apply(lambda x: cn_dict[x])\n",
    "# fake full name for consistency with boilerplate NMT code\n",
    "test_df['fullname_true'] = test_df['fullname']\n",
    "test_df['target'] = 0\n",
    "\n",
    "cols = ['id','fullname','fullname_true','target','country']\n",
    "train_df = train_df[cols].set_index('id')\n",
    "test_df = test_df[cols].set_index('id')\n",
    "\n",
    "train_df.to_csv('../data/proc_train.csv')\n",
    "test_df.to_csv('../data/proc_test.csv')\n",
    "\"\"\"\n",
    "\n",
    "def cleaner(text):\n",
    "    new_text = text\n",
    "    new_text = re.sub(\"[_\\n/]\", \" \", new_text)\n",
    "    new_text = re.sub(\"[12345?[|]\", \"\", new_text)\n",
    "    new_text = re.sub(\"\", \"\", new_text)\n",
    "    return new_text\n",
    "\n",
    "def tokenize(text):\n",
    "    return list(cleaner(text))\n",
    "\n",
    "UNK_TOKEN = \"!\"\n",
    "PAD_TOKEN = \"_\"    \n",
    "SOS_TOKEN = \"[\"\n",
    "EOS_TOKEN = \"]\"\n",
    "LOWER = False\n",
    "\n",
    "ID = data.Field(sequential=False,\n",
    "                use_vocab=False)\n",
    "\n",
    "NAMES = data.Field(tokenize=tokenize, \n",
    "                 batch_first=True,\n",
    "                 lower=LOWER,\n",
    "                 include_lengths=True,\n",
    "                 unk_token=UNK_TOKEN,\n",
    "                 pad_token=PAD_TOKEN,\n",
    "                 init_token=None,\n",
    "                 eos_token=EOS_TOKEN)\n",
    "\n",
    "TRG_NAMES = data.Field(tokenize=tokenize, \n",
    "                       batch_first=True,\n",
    "                       lower=LOWER,\n",
    "                       include_lengths=True,\n",
    "                       unk_token=UNK_TOKEN,\n",
    "                       pad_token=PAD_TOKEN,\n",
    "                       init_token=SOS_TOKEN,\n",
    "                       eos_token=EOS_TOKEN)\n",
    "\n",
    "LBL = data.Field(sequential=False,\n",
    "                 use_vocab=False)\n",
    "\n",
    "CNT = data.Field(sequential=False,\n",
    "                 use_vocab=False)\n",
    "\n",
    "datafields = [(\"id\", ID),\n",
    "              (\"src\", NAMES),\n",
    "              (\"trg\", TRG_NAMES),\n",
    "              (\"clf\", LBL),\n",
    "              (\"cn\", CNT)\n",
    "             ]\n",
    "\n",
    "train_data = data.TabularDataset(path=\"../data/proc_train.csv\",\n",
    "                                 format='csv',\n",
    "                                 skip_header=True,\n",
    "                                 fields=datafields)\n",
    "\n",
    "train_data, valid_data = train_data.split(split_ratio=0.9,\n",
    "                                          stratified=True,\n",
    "                                          strata_field='cn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T11:38:02.554490Z",
     "start_time": "2018-10-20T11:37:42.922824Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MIN_FREQ = 1  # NOTE: we limit the vocabulary to frequent words for speed\n",
    "NAMES.build_vocab(train_data.src, min_freq=MIN_FREQ)\n",
    "TRG_NAMES.build_vocab(train_data.trg, min_freq=MIN_FREQ)\n",
    "PAD_INDEX = TRG_NAMES.vocab.stoi[PAD_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:15:29.927014Z",
     "start_time": "2018-10-19T12:15:29.922118Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_data_info(train_data, valid_data, src_field):\n",
    "    \"\"\" This prints some useful stuff about our data sets. \"\"\"\n",
    "\n",
    "    print(\"Data set sizes (number of sentence pairs):\")\n",
    "    print('train', len(train_data))\n",
    "    print('valid', len(valid_data))\n",
    "    # print('test', len(test_data), \"\\n\")\n",
    "\n",
    "    print(\"First training example:\")\n",
    "    print(\"src:\", \" \".join(vars(train_data[0])['src']))\n",
    "    # print(\"trg:\", \" \".join(vars(train_data[0])['trg']), \"\\n\")\n",
    "\n",
    "    print(\"Most common letters:\")\n",
    "    print(\"\\n\".join([\"%10s %10d\" % x for x in src_field.vocab.freqs.most_common(10)]), \"\\n\")\n",
    "\n",
    "    print(\"First 10 letters (src):\")\n",
    "    print(\"\\n\".join(\n",
    "        '%02d %s' % (i, t) for i, t in enumerate(src_field.vocab.itos[:10])), \"\\n\")\n",
    "    \n",
    "    print(\"Number of letters:\", len(src_field.vocab))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:15:29.943129Z",
     "start_time": "2018-10-19T12:15:29.929041Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set sizes (number of sentence pairs):\n",
      "train 1592882\n",
      "valid 398222\n",
      "First training example:\n",
      "src:                                \n",
      "Most common letters:\n",
      "             5071360\n",
      "             3138102\n",
      "             2930829\n",
      "              2925170\n",
      "             2731778\n",
      "             2320880\n",
      "             1940045\n",
      "             1835899\n",
      "             1635395\n",
      "             1419430 \n",
      "\n",
      "First 10 letters (src):\n",
      "00 !\n",
      "01 _\n",
      "02 ]\n",
      "03 \n",
      "04 \n",
      "05 \n",
      "06  \n",
      "07 \n",
      "08 \n",
      "09  \n",
      "\n",
      "Number of letters: 76\n"
     ]
    }
   ],
   "source": [
    "print_data_info(train_data, valid_data, NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T12:37:00.172019Z",
     "start_time": "2018-10-20T12:37:00.166397Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.4557, -0.2327]), tensor([ 0,  1]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.randn((2,2,)),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T12:44:23.864072Z",
     "start_time": "2018-10-20T12:44:23.855315Z"
    },
    "code_folding": [
     0,
     39
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, src_lengths, max_len=100, sos_index=1, eos_index=None):\n",
    "    \"\"\"Greedily decode a sentence.\"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths)\n",
    "        prev_y = torch.ones(1, 1).fill_(sos_index).type_as(src)\n",
    "        trg_mask = torch.ones_like(prev_y)\n",
    "\n",
    "    output = []\n",
    "    attention_scores = []\n",
    "    hidden = None\n",
    "\n",
    "    for i in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            out, hidden, pre_output = model.decode(\n",
    "              encoder_hidden, encoder_final, src_mask,\n",
    "              prev_y, trg_mask, hidden)\n",
    "\n",
    "            # we predict from the pre-output layer, which is\n",
    "            # a combination of Decoder state, prev emb, and context\n",
    "            prob = model.generator(pre_output[:, -1])\n",
    "\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data.item()\n",
    "        output.append(next_word)\n",
    "        prev_y = torch.ones(1, 1).type_as(src).fill_(next_word)\n",
    "        attention_scores.append(model.decoder.attention.alphas.cpu().numpy())\n",
    "    \n",
    "    output = np.array(output)\n",
    "        \n",
    "    # cut off everything starting from </s> \n",
    "    # (only when eos_index provided)\n",
    "    if eos_index is not None:\n",
    "        first_eos = np.where(output==eos_index)[0]\n",
    "        if len(first_eos) > 0:\n",
    "            output = output[:first_eos[0]]      \n",
    "    \n",
    "    return output, np.concatenate(attention_scores, axis=1)\n",
    "\n",
    "def greedy_decode_batch(model,\n",
    "                        src, src_mask, src_lengths,\n",
    "                        max_len=100,\n",
    "                        sos_index=1, eos_index=None):\n",
    "    \"\"\"Greedily decode a sentence.\"\"\"\n",
    "    batch_size = src.size(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths)\n",
    "        prev_y = torch.ones(batch_size, 1).fill_(sos_index).type_as(src)\n",
    "        trg_mask = torch.ones_like(prev_y)\n",
    "\n",
    "    output = []\n",
    "    # attention_scores = []\n",
    "    hidden = None\n",
    "\n",
    "    for i in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            out, hidden, pre_output = model.decode(\n",
    "              encoder_hidden, encoder_final, src_mask,\n",
    "              prev_y, trg_mask, hidden)\n",
    "\n",
    "            # we predict from the pre-output layer, which is\n",
    "            # a combination of Decoder state, prev emb, and context\n",
    "            prob = model.generator(pre_output[:, -1])\n",
    "\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data\n",
    "        output.append(next_word.cpu().numpy())\n",
    "        prev_y = next_word.unsqueeze(dim=1)\n",
    "        # attention_scores.append(model.decoder.attention.alphas.cpu().numpy())\n",
    "    \n",
    "    output = np.array(output)\n",
    "        \n",
    "    # cut off everything starting from </s> \n",
    "    # (only when eos_index provided)\n",
    "    # if eos_index is not None:\n",
    "    #    first_eos = np.where(output==eos_index)[0]\n",
    "    #    if len(first_eos) > 0:\n",
    "    #        output = output[:first_eos[0]]      \n",
    "    \n",
    "    output = np.stack(output).T\n",
    "    \n",
    "    return output #, np.concatenate(attention_scores, axis=1)\n",
    "\n",
    "def lookup_words(x, vocab=None):\n",
    "    if vocab is not None:\n",
    "        x = [vocab.itos[i] for i in x]\n",
    "\n",
    "    return [str(t) for t in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T15:06:43.228260Z",
     "start_time": "2018-10-20T15:06:42.825347Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for batch in valid_iter_batch:\n",
    "    batch = rebatch(PAD_INDEX,batch=batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T12:39:24.827031Z",
     "start_time": "2018-10-20T12:39:24.823911Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 11])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T12:39:33.227291Z",
     "start_time": "2018-10-20T12:39:33.223954Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "src_eos_index = NAMES.vocab.stoi[EOS_TOKEN]\n",
    "trg_sos_index = TRG_NAMES.vocab.stoi[SOS_TOKEN]\n",
    "trg_eos_index = TRG_NAMES.vocab.stoi[EOS_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T12:44:25.595661Z",
     "start_time": "2018-10-20T12:44:25.478704Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = greedy_decode_batch(\n",
    "  model, batch.src, batch.src_mask, batch.src_lengths,\n",
    "  max_len=100, sos_index=trg_sos_index, eos_index=trg_eos_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T12:44:29.630281Z",
     "start_time": "2018-10-20T12:44:29.627178Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48, 28, 31, ...,  1,  1,  1],\n",
       "       [ 9, 11, 22, ...,  1,  1,  1],\n",
       "       [12, 29, 21, ...,  1,  1,  1],\n",
       "       ...,\n",
       "       [35,  6, 35, ...,  1,  1,  1],\n",
       "       [10,  6, 10, ...,  1,  1,  1],\n",
       "       [26,  6, 54, ...,  1,  1,  1]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T12:43:37.018825Z",
     "start_time": "2018-10-20T12:43:37.015868Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T12:45:32.420568Z",
     "start_time": "2018-10-20T12:45:32.416266Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T12:45:30.595345Z",
     "start_time": "2018-10-20T12:45:30.591374Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T12:48:30.621381Z",
     "start_time": "2018-10-20T12:48:30.617391Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Src :   ]______\n",
      "Trg :   ]_______\n",
      "Pred:   ]_______________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0,batch.src.size(0))\n",
    "src = batch.src.cpu().numpy()[idx, :]\n",
    "trg = batch.trg_y.cpu().numpy()[idx, :]\n",
    "res = result[idx]        \n",
    "print(\"Src : \", \"\".join(lookup_words(src, vocab=NAMES.vocab)))\n",
    "print(\"Trg : \", \"\".join(lookup_words(trg, vocab=TRG_NAMES.vocab)))\n",
    "print(\"Pred: \", \"\".join(lookup_words(res, vocab=TRG_NAMES.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T12:25:27.591034Z",
     "start_time": "2018-10-20T12:25:27.587373Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 1]\n",
       "\t[.id]:[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
       "\t[.src]:('[torch.cuda.LongTensor of size 1x33 (GPU 0)]', '[torch.cuda.LongTensor of size 1 (GPU 0)]')\n",
       "\t[.trg]:('[torch.cuda.LongTensor of size 1x34 (GPU 0)]', '[torch.cuda.LongTensor of size 1 (GPU 0)]')\n",
       "\t[.clf]:[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
       "\t[.cn]:[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T15:07:04.302601Z",
     "start_time": "2018-10-20T15:07:04.298269Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 11]), torch.Size([512, 1, 11]), torch.Size([512]))"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.src.shape,batch.src_mask.shape,batch.src_lengths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T15:24:08.920397Z",
     "start_time": "2018-10-20T15:24:08.913843Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classifier = nn.Sequential((nn.Linear((1+int(1)) * 256, 300)),\n",
    "                              nn.Dropout(p=0.1),\n",
    "                              nn.LeakyReLU(),\n",
    "                              nn.Linear(300, 128),\n",
    "                              nn.Dropout(p=0.1),\n",
    "                              nn.LeakyReLU(),\n",
    "                              nn.Linear(128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T15:24:13.992122Z",
     "start_time": "2018-10-20T15:24:13.874137Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 3])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(encoder_hidden.cpu()).mean(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T15:08:09.579770Z",
     "start_time": "2018-10-20T15:08:09.574430Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoder_hidden, encoder_final = model.encode(batch.src,\n",
    "                                              batch.src_mask,\n",
    "                                              batch.src_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T15:08:18.071227Z",
     "start_time": "2018-10-20T15:08:18.068403Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 11, 512]), torch.Size([1, 512, 512]))"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden.shape,encoder_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:23:38.503052Z",
     "start_time": "2018-10-20T13:23:38.482914Z"
    },
    "code_folding": [
     0,
     34,
     87,
     129
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(data_iter,\n",
    "              model,\n",
    "              loss_compute,\n",
    "              print_every=50,\n",
    "              num_batches=100):\n",
    "    \"\"\"Standard Training and Logging Function\"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    print_tokens = 0\n",
    "\n",
    "    with tqdm(total=num_batches) as pbar:\n",
    "        for i, batch in enumerate(data_iter, 1):\n",
    "\n",
    "            out, _, pre_output = model.forward(batch.src, batch.trg,\n",
    "                                               batch.src_mask, batch.trg_mask,\n",
    "                                               batch.src_lengths, batch.trg_lengths)\n",
    "            loss = loss_compute(pre_output, batch.trg_y, batch.nseqs)\n",
    "            total_loss += loss\n",
    "            total_tokens += batch.ntokens\n",
    "            print_tokens += batch.ntokens\n",
    "\n",
    "            if model.training and i % print_every == 0:\n",
    "                elapsed = time.time() - start\n",
    "                print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
    "                        (i, loss / batch.nseqs, print_tokens / elapsed))\n",
    "                start = time.time()\n",
    "                print_tokens = 0\n",
    "            \n",
    "            pbar.update(1)\n",
    "                \n",
    "    return math.exp(total_loss / float(total_tokens))\n",
    "\n",
    "def train(model,\n",
    "          num_epochs=10,\n",
    "          lr=2*1e-4,\n",
    "          print_every=100):\n",
    "    \"\"\"Train a model on IWSLT\"\"\"\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        model.cuda()\n",
    "\n",
    "    # optionally add label smoothing; see the Annotated Transformer\n",
    "    # criterion = nn.NLLLoss(reduce=, ignore_index=PAD_INDEX)\n",
    "    criterion = nn.NLLLoss(size_average=False, ignore_index=0)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    dev_perplexities = []\n",
    "    dev_preds = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "      \n",
    "        print(\"Epoch\", epoch)\n",
    "        print('Training the model')\n",
    "        model.train()\n",
    "        \"\"\"\n",
    "        train_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in train_iter), \n",
    "                                     model,\n",
    "                                     SimpleLossCompute(model.generator, criterion, optim),\n",
    "                                     print_every=print_every,\n",
    "                                     num_batches=len(train_iter))\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print('Evaluating the model')\n",
    "            \"\"\"\n",
    "            print_examples((rebatch(PAD_INDEX, x) for x in valid_iter), \n",
    "                           model, n=10, src_vocab=NAMES.vocab, trg_vocab=TRG_NAMES.vocab)        \n",
    "            \"\"\"\n",
    "            dev_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in valid_iter_batch), \n",
    "                                       model, \n",
    "                                       SimpleLossCompute(model.generator, criterion, None),\n",
    "                                       num_batches=len(valid_iter_batch))\n",
    "            \n",
    "\n",
    "            preds = predict((rebatch(PAD_INDEX, x) for x in valid_iter_batch), \n",
    "                            model, max_len=70, src_vocab=NAMES.vocab, trg_vocab=TRG_NAMES.vocab,\n",
    "                            num_batches=len(valid_iter_batch)) \n",
    "            \n",
    "            dev_preds.extend(preds)\n",
    "            \n",
    "            print(\"Validation perplexity: %f\" % dev_perplexity)\n",
    "            dev_perplexities.append(dev_perplexity)\n",
    "        \n",
    "    return dev_perplexities,dev_preds\n",
    "\n",
    "def print_examples(example_iter, model, n=2, max_len=100, \n",
    "                   sos_index=1, \n",
    "                   src_eos_index=None, \n",
    "                   trg_eos_index=None, \n",
    "                   src_vocab=None, trg_vocab=None):\n",
    "    \"\"\"Prints N examples. Assumes batch size of 1.\"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    print()\n",
    "    \n",
    "    if src_vocab is not None and trg_vocab is not None:\n",
    "        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n",
    "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
    "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
    "    else:\n",
    "        src_eos_index = None\n",
    "        trg_sos_index = 1\n",
    "        trg_eos_index = None\n",
    "        \n",
    "    for i, batch in enumerate(example_iter):\n",
    "      \n",
    "        src = batch.src.cpu().numpy()[0, :]\n",
    "        trg = batch.trg_y.cpu().numpy()[0, :]\n",
    "\n",
    "        # remove </s> (if it is there)\n",
    "        src = src[:-1] if src[-1] == src_eos_index else src\n",
    "        trg = trg[:-1] if trg[-1] == trg_eos_index else trg      \n",
    "      \n",
    "        result, _ = greedy_decode(\n",
    "          model, batch.src, batch.src_mask, batch.src_lengths,\n",
    "          max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index)\n",
    "        print(\"Example #%d\" % (i+1))\n",
    "        print(\"Src : \", \" \".join(lookup_words(src, vocab=src_vocab)))\n",
    "        print(\"Trg : \", \" \".join(lookup_words(trg, vocab=trg_vocab)))\n",
    "        print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab)))\n",
    "        print()\n",
    "        \n",
    "        count += 1\n",
    "        if count == n:\n",
    "            break\n",
    "            \n",
    "def predict(example_iter, model, max_len=100, \n",
    "            sos_index=1, \n",
    "            src_eos_index=None, \n",
    "            trg_eos_index=None, \n",
    "            src_vocab=None, trg_vocab=None,\n",
    "            num_batches=100):\n",
    "    \"\"\"Prints N examples. Assumes batch size of 1.\"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    print()\n",
    "    \n",
    "    if src_vocab is not None and trg_vocab is not None:\n",
    "        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n",
    "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
    "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
    "    else:\n",
    "        src_eos_index = None\n",
    "        trg_sos_index = 1\n",
    "        trg_eos_index = None\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    with tqdm(total=num_batches) as pbar:\n",
    "        for i, batch in enumerate(example_iter):\n",
    "\n",
    "            output = greedy_decode_batch(\n",
    "              model, batch.src, batch.src_mask, batch.src_lengths,\n",
    "              max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index)\n",
    "\n",
    "            # cut off everything starting from </s> \n",
    "            # (only when eos_index provided)\n",
    "            if trg_eos_index is not None:\n",
    "                # iterate over sentence predictions and cut off from eos\n",
    "                for pred in output:\n",
    "                    first_eos = np.where(pred==trg_eos_index)[0]\n",
    "                    if len(first_eos) > 0:\n",
    "                        # produce sentences\n",
    "                        preds.append(\"\".join(lookup_words(pred[:first_eos[0]],\n",
    "                                             vocab=TRG_NAMES.vocab)))\n",
    "            pbar.update(1)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T12:25:08.072007Z",
     "start_time": "2018-10-20T12:25:08.067238Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_iter = data.BucketIterator(train_data,\n",
    "                                 batch_size=512,\n",
    "                                 train=True, \n",
    "                                 sort_within_batch=True, \n",
    "                                 sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                                 repeat=False,\n",
    "                                 device=DEVICE,\n",
    "                                 shuffle=True)\n",
    "\n",
    "valid_iter = data.Iterator(valid_data,\n",
    "                           batch_size=1,\n",
    "                           train=False,\n",
    "                           sort=False,\n",
    "                           repeat=False, \n",
    "                           device=DEVICE)\n",
    "\n",
    "valid_iter_batch = data.Iterator(valid_data,\n",
    "                           batch_size=512,\n",
    "                           train=False,\n",
    "                           sort_within_batch=True,\n",
    "                           sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                           repeat=False, \n",
    "                           device=DEVICE,\n",
    "                           shuffle=False)\n",
    "\n",
    "def rebatch(pad_idx, batch):\n",
    "    \"\"\"Wrap torchtext batch into our own Batch class for pre-processing\"\"\"\n",
    "    return Batch(batch.src, batch.trg, pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T12:08:20.302900Z",
     "start_time": "2018-10-20T12:08:15.680769Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_ids = []\n",
    "for b in valid_iter:\n",
    "    val_ids.extend(list(b.id.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:12:05.449726Z",
     "start_time": "2018-10-20T13:12:05.432790Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1763541,\n",
       " 361081,\n",
       " 1361399,\n",
       " 175491,\n",
       " 586990,\n",
       " 629776,\n",
       " 1448272,\n",
       " 1177837,\n",
       " 14087,\n",
       " 436394,\n",
       " 1058886,\n",
       " 634640,\n",
       " 1170735,\n",
       " 1238753,\n",
       " 1264272,\n",
       " 234061,\n",
       " 1367493,\n",
       " 1291992,\n",
       " 1208654,\n",
       " 1422147,\n",
       " 1980736,\n",
       " 221351,\n",
       " 1328396,\n",
       " 564979,\n",
       " 205771,\n",
       " 1895036,\n",
       " 704375,\n",
       " 1478253,\n",
       " 1799704,\n",
       " 1253527,\n",
       " 1127169,\n",
       " 1632428,\n",
       " 1896440,\n",
       " 1880670,\n",
       " 801157,\n",
       " 796851,\n",
       " 1797501,\n",
       " 1478725,\n",
       " 1102253,\n",
       " 952937,\n",
       " 912277,\n",
       " 1201027,\n",
       " 979721,\n",
       " 775371,\n",
       " 755955,\n",
       " 1439509,\n",
       " 100407,\n",
       " 88135,\n",
       " 1805274,\n",
       " 1519072,\n",
       " 1679208,\n",
       " 361042,\n",
       " 104203,\n",
       " 184267,\n",
       " 369433,\n",
       " 1713690,\n",
       " 1792137,\n",
       " 1017153,\n",
       " 1311293,\n",
       " 534,\n",
       " 768462,\n",
       " 407381,\n",
       " 417441,\n",
       " 68729,\n",
       " 324638,\n",
       " 64400,\n",
       " 1468633,\n",
       " 1245941,\n",
       " 1920579,\n",
       " 544855,\n",
       " 589843,\n",
       " 220441,\n",
       " 296686,\n",
       " 196222,\n",
       " 1247550,\n",
       " 1326348,\n",
       " 1583410,\n",
       " 1074569,\n",
       " 796533,\n",
       " 1688353,\n",
       " 1046654,\n",
       " 1552859,\n",
       " 409163,\n",
       " 675628,\n",
       " 1406371,\n",
       " 1640126,\n",
       " 624860,\n",
       " 1077734,\n",
       " 1966146,\n",
       " 567139,\n",
       " 56144,\n",
       " 364612,\n",
       " 1356885,\n",
       " 84280,\n",
       " 357177,\n",
       " 961406,\n",
       " 1153893,\n",
       " 1192598,\n",
       " 1450489,\n",
       " 1875393,\n",
       " 1107958,\n",
       " 1389221,\n",
       " 495972,\n",
       " 1272779,\n",
       " 1849306,\n",
       " 1022732,\n",
       " 6653,\n",
       " 1686546,\n",
       " 74471,\n",
       " 1388655,\n",
       " 709784,\n",
       " 1176397,\n",
       " 373666,\n",
       " 1239738,\n",
       " 968760,\n",
       " 1308668,\n",
       " 833241,\n",
       " 1929095,\n",
       " 295644,\n",
       " 1978849,\n",
       " 765795,\n",
       " 694974,\n",
       " 134502,\n",
       " 1571913,\n",
       " 251736,\n",
       " 1907360,\n",
       " 1099836,\n",
       " 345112,\n",
       " 1460678,\n",
       " 1543920,\n",
       " 362074,\n",
       " 1312259,\n",
       " 1920249,\n",
       " 689929,\n",
       " 737912,\n",
       " 304263,\n",
       " 1425864,\n",
       " 1085961,\n",
       " 484869,\n",
       " 1031362,\n",
       " 1343202,\n",
       " 1788238,\n",
       " 102120,\n",
       " 1826377,\n",
       " 1823424,\n",
       " 1940816,\n",
       " 524880,\n",
       " 1441143,\n",
       " 585761,\n",
       " 646197,\n",
       " 1751705,\n",
       " 1854937,\n",
       " 1914705,\n",
       " 103669,\n",
       " 1027770,\n",
       " 1211572,\n",
       " 1740394,\n",
       " 664361,\n",
       " 1699179,\n",
       " 96206,\n",
       " 1332931,\n",
       " 1055193,\n",
       " 592988,\n",
       " 1984660,\n",
       " 573178,\n",
       " 1650079,\n",
       " 438787,\n",
       " 1937342,\n",
       " 1638056,\n",
       " 1549631,\n",
       " 446253,\n",
       " 126802,\n",
       " 1348967,\n",
       " 1610732,\n",
       " 1630044,\n",
       " 1025378,\n",
       " 152675,\n",
       " 1917733,\n",
       " 62965,\n",
       " 331061,\n",
       " 1556120,\n",
       " 1466929,\n",
       " 713188,\n",
       " 290315,\n",
       " 627084,\n",
       " 839093,\n",
       " 1939189,\n",
       " 250972,\n",
       " 1648972,\n",
       " 365599,\n",
       " 1356976,\n",
       " 838251,\n",
       " 818040,\n",
       " 1425519,\n",
       " 1287,\n",
       " 327837,\n",
       " 883939,\n",
       " 590021,\n",
       " 400897,\n",
       " 1406737,\n",
       " 1802670,\n",
       " 1184423,\n",
       " 1100855,\n",
       " 576088,\n",
       " 137257,\n",
       " 50794,\n",
       " 1772253,\n",
       " 1150138,\n",
       " 1242281,\n",
       " 222468,\n",
       " 482451,\n",
       " 1676139,\n",
       " 1844656,\n",
       " 311426,\n",
       " 988151,\n",
       " 468130,\n",
       " 1642098,\n",
       " 173091,\n",
       " 1495697,\n",
       " 366621,\n",
       " 1577175,\n",
       " 512504,\n",
       " 12923,\n",
       " 574995,\n",
       " 1457800,\n",
       " 1140167,\n",
       " 795900,\n",
       " 1585648,\n",
       " 1658574,\n",
       " 1662973,\n",
       " 1066533,\n",
       " 626441,\n",
       " 564187,\n",
       " 1589515,\n",
       " 1831237,\n",
       " 1139147,\n",
       " 461723,\n",
       " 1978498,\n",
       " 4683,\n",
       " 1777988,\n",
       " 354074,\n",
       " 1171959,\n",
       " 369596,\n",
       " 446649,\n",
       " 422905,\n",
       " 749409,\n",
       " 474396,\n",
       " 1636163,\n",
       " 1418670,\n",
       " 1943000,\n",
       " 952654,\n",
       " 1092153,\n",
       " 582494,\n",
       " 1496777,\n",
       " 253485,\n",
       " 1976068,\n",
       " 635969,\n",
       " 127727,\n",
       " 1175444,\n",
       " 40388,\n",
       " 687620,\n",
       " 1101993,\n",
       " 753469,\n",
       " 1640969,\n",
       " 336688,\n",
       " 1249347,\n",
       " 713673,\n",
       " 1362462,\n",
       " 1478466,\n",
       " 874721,\n",
       " 1640833,\n",
       " 1801172,\n",
       " 1676576,\n",
       " 657102,\n",
       " 1210233,\n",
       " 1587955,\n",
       " 879244,\n",
       " 640497,\n",
       " 1029574,\n",
       " 1492706,\n",
       " 1685598,\n",
       " 1238228,\n",
       " 1789103,\n",
       " 522336,\n",
       " 13901,\n",
       " 1213737,\n",
       " 149001,\n",
       " 750484,\n",
       " 905069,\n",
       " 1831811,\n",
       " 1194,\n",
       " 36757,\n",
       " 1481518,\n",
       " 408838,\n",
       " 46831,\n",
       " 1742404,\n",
       " 1474946,\n",
       " 1161759,\n",
       " 721440,\n",
       " 193511,\n",
       " 1026724,\n",
       " 1701355,\n",
       " 1605264,\n",
       " 1093862,\n",
       " 213441,\n",
       " 228005,\n",
       " 1115443,\n",
       " 1054760,\n",
       " 254658,\n",
       " 638706,\n",
       " 36841,\n",
       " 954513,\n",
       " 1485696,\n",
       " 1761370,\n",
       " 1758848,\n",
       " 1909869,\n",
       " 694436,\n",
       " 1963045,\n",
       " 307365,\n",
       " 1224081,\n",
       " 122937,\n",
       " 1203554,\n",
       " 1347282,\n",
       " 477422,\n",
       " 1866146,\n",
       " 981090,\n",
       " 1678868,\n",
       " 586598,\n",
       " 716622,\n",
       " 997315,\n",
       " 657028,\n",
       " 1122898,\n",
       " 798834,\n",
       " 1098749,\n",
       " 218171,\n",
       " 430292,\n",
       " 1851924,\n",
       " 1345745,\n",
       " 1354535,\n",
       " 1581182,\n",
       " 1215159,\n",
       " 1934725,\n",
       " 1968338,\n",
       " 1037109,\n",
       " 970777,\n",
       " 113162,\n",
       " 1444282,\n",
       " 823573,\n",
       " 1811520,\n",
       " 1061223,\n",
       " 1555724,\n",
       " 1167680,\n",
       " 1254876,\n",
       " 780974,\n",
       " 617143,\n",
       " 244658,\n",
       " 629059,\n",
       " 43063,\n",
       " 139578,\n",
       " 1451487,\n",
       " 1590229,\n",
       " 1499965,\n",
       " 1946694,\n",
       " 1679434,\n",
       " 1076449,\n",
       " 1140061,\n",
       " 319452,\n",
       " 1036402,\n",
       " 1140687,\n",
       " 466813,\n",
       " 1550940,\n",
       " 8829,\n",
       " 603921,\n",
       " 12650,\n",
       " 248843,\n",
       " 409727,\n",
       " 49315,\n",
       " 1823123,\n",
       " 1275892,\n",
       " 1498369,\n",
       " 1322538,\n",
       " 1344529,\n",
       " 1304789,\n",
       " 1591067,\n",
       " 1049742,\n",
       " 28377,\n",
       " 1107872,\n",
       " 500853,\n",
       " 88205,\n",
       " 32053,\n",
       " 14691,\n",
       " 1120127,\n",
       " 1154689,\n",
       " 1390961,\n",
       " 1909863,\n",
       " 127503,\n",
       " 1292162,\n",
       " 665607,\n",
       " 1798039,\n",
       " 1777575,\n",
       " 1168940,\n",
       " 1179249,\n",
       " 1911090,\n",
       " 1849383,\n",
       " 469970,\n",
       " 355155,\n",
       " 638599,\n",
       " 507247,\n",
       " 1439816,\n",
       " 1828942,\n",
       " 1034013,\n",
       " 524279,\n",
       " 1655195,\n",
       " 92181,\n",
       " 1139260,\n",
       " 555810,\n",
       " 813807,\n",
       " 1910497,\n",
       " 404067,\n",
       " 1675757,\n",
       " 739967,\n",
       " 1327921,\n",
       " 1621577,\n",
       " 1549051,\n",
       " 1908792,\n",
       " 1338274,\n",
       " 817085,\n",
       " 1243338,\n",
       " 656415,\n",
       " 710131,\n",
       " 1529560,\n",
       " 1881332,\n",
       " 24738,\n",
       " 1960198,\n",
       " 255250,\n",
       " 245724,\n",
       " 1680302,\n",
       " 1752217,\n",
       " 756102,\n",
       " 873884,\n",
       " 450378,\n",
       " 1370950,\n",
       " 1577068,\n",
       " 1071122,\n",
       " 996208,\n",
       " 1191512,\n",
       " 338600,\n",
       " 727540,\n",
       " 587773,\n",
       " 1877781,\n",
       " 1436983,\n",
       " 1200839,\n",
       " 1103414,\n",
       " 1450130,\n",
       " 1430267,\n",
       " 1621159,\n",
       " 1032216,\n",
       " 476846,\n",
       " 14783,\n",
       " 1637024,\n",
       " 1113767,\n",
       " 898241,\n",
       " 198419,\n",
       " 1542466,\n",
       " 1164159,\n",
       " 871411,\n",
       " 1404578,\n",
       " 466049,\n",
       " 936662,\n",
       " 1878190,\n",
       " 1574871,\n",
       " 1549252,\n",
       " 1673979,\n",
       " 306142,\n",
       " 1901130,\n",
       " 1730489,\n",
       " 525306,\n",
       " 637747,\n",
       " 1215811,\n",
       " 1243454,\n",
       " 1583553,\n",
       " 935869,\n",
       " 15787,\n",
       " 317998,\n",
       " 1632295,\n",
       " 615637,\n",
       " 1814465,\n",
       " 1906248,\n",
       " 1574360,\n",
       " 1111679,\n",
       " 1046006,\n",
       " 741387,\n",
       " 798671,\n",
       " 1494509,\n",
       " 1134775,\n",
       " 11257,\n",
       " 1382552,\n",
       " 1433246,\n",
       " 1910041,\n",
       " 1790458,\n",
       " 904754,\n",
       " 1385799,\n",
       " 660310,\n",
       " 1928213,\n",
       " 1595533,\n",
       " 948293,\n",
       " 1788537,\n",
       " 997337,\n",
       " 930818,\n",
       " 661326,\n",
       " 1148050,\n",
       " 1146437,\n",
       " 1541071,\n",
       " 1205596,\n",
       " 691876,\n",
       " 535770,\n",
       " 1808793,\n",
       " 409275,\n",
       " 701772,\n",
       " 1548165,\n",
       " 1981893,\n",
       " 1374431,\n",
       " 1063719,\n",
       " 1483156,\n",
       " 1788337,\n",
       " 1868597,\n",
       " 1081934,\n",
       " 1699543,\n",
       " 1651789,\n",
       " 1160621,\n",
       " 921922,\n",
       " 357266,\n",
       " 610572,\n",
       " 676701,\n",
       " 1886250,\n",
       " 1148196,\n",
       " 1391644,\n",
       " 900173,\n",
       " 642628,\n",
       " 80251,\n",
       " 346910,\n",
       " 253514,\n",
       " 610402,\n",
       " 1635110,\n",
       " 493679,\n",
       " 21476,\n",
       " 1922089,\n",
       " 388715,\n",
       " 956973,\n",
       " 1573065,\n",
       " 50227,\n",
       " 261633,\n",
       " 578398,\n",
       " 1987379,\n",
       " 1953372,\n",
       " 1661877,\n",
       " 1074109,\n",
       " 144557,\n",
       " 240945,\n",
       " 902989,\n",
       " 589738,\n",
       " 1975253,\n",
       " 743648,\n",
       " 1984789,\n",
       " 1490357,\n",
       " 1493956,\n",
       " 250473,\n",
       " 1760300,\n",
       " 573754,\n",
       " 569776,\n",
       " 806751,\n",
       " 158960,\n",
       " 1520801,\n",
       " 790363,\n",
       " 1893325,\n",
       " 582831,\n",
       " 1663132,\n",
       " 1285577,\n",
       " 973374,\n",
       " 1081157,\n",
       " 904068,\n",
       " 1915109,\n",
       " 1068049,\n",
       " 35702,\n",
       " 1089309,\n",
       " 79611,\n",
       " 156406,\n",
       " 1118845,\n",
       " 407940,\n",
       " 1613984,\n",
       " 1566426,\n",
       " 1300368,\n",
       " 1344127,\n",
       " 783548,\n",
       " 833099,\n",
       " 1232467,\n",
       " 34768,\n",
       " 1026003,\n",
       " 1089662,\n",
       " 932370,\n",
       " 1378649,\n",
       " 323782,\n",
       " 272816,\n",
       " 635208,\n",
       " 326278,\n",
       " 922,\n",
       " 655689,\n",
       " 1977177,\n",
       " 1899783,\n",
       " 76634,\n",
       " 781088,\n",
       " 652027,\n",
       " 209175,\n",
       " 732376,\n",
       " 1131606,\n",
       " 1926166,\n",
       " 1697971,\n",
       " 1750907,\n",
       " 1187053,\n",
       " 664591,\n",
       " 1802789,\n",
       " 1277581,\n",
       " 595276,\n",
       " 1696079,\n",
       " 227659,\n",
       " 1600551,\n",
       " 325365,\n",
       " 1504786,\n",
       " 743780,\n",
       " 1861323,\n",
       " 151402,\n",
       " 1543146,\n",
       " 795805,\n",
       " 942616,\n",
       " 318562,\n",
       " 1347002,\n",
       " 593932,\n",
       " 330952,\n",
       " 482677,\n",
       " 1836496,\n",
       " 1514133,\n",
       " 968434,\n",
       " 1315819,\n",
       " 825480,\n",
       " 1415546,\n",
       " 1281417,\n",
       " 1004384,\n",
       " 1898448,\n",
       " 882375,\n",
       " 1436438,\n",
       " 411753,\n",
       " 995971,\n",
       " 1688346,\n",
       " 933470,\n",
       " 848917,\n",
       " 1575581,\n",
       " 872398,\n",
       " 945259,\n",
       " 502887,\n",
       " 461384,\n",
       " 947650,\n",
       " 1643949,\n",
       " 1124367,\n",
       " 1959743,\n",
       " 419427,\n",
       " 142359,\n",
       " 248591,\n",
       " 666680,\n",
       " 1251068,\n",
       " 871820,\n",
       " 1126047,\n",
       " 104262,\n",
       " 274086,\n",
       " 853748,\n",
       " 1842747,\n",
       " 1828265,\n",
       " 1392539,\n",
       " 895481,\n",
       " 1322709,\n",
       " 1258109,\n",
       " 1692353,\n",
       " 590133,\n",
       " 1512770,\n",
       " 385117,\n",
       " 189953,\n",
       " 990207,\n",
       " 1716294,\n",
       " 1586891,\n",
       " 808690,\n",
       " 561329,\n",
       " 1150592,\n",
       " 1662010,\n",
       " 853608,\n",
       " 998339,\n",
       " 936239,\n",
       " 1625017,\n",
       " 147711,\n",
       " 1852604,\n",
       " 236709,\n",
       " 852098,\n",
       " 134550,\n",
       " 928636,\n",
       " 1355427,\n",
       " 767176,\n",
       " 721475,\n",
       " 1572670,\n",
       " 953586,\n",
       " 1062492,\n",
       " 980350,\n",
       " 969942,\n",
       " 936931,\n",
       " 370342,\n",
       " 1770847,\n",
       " 729868,\n",
       " 1786371,\n",
       " 1516177,\n",
       " 788520,\n",
       " 1114469,\n",
       " 1878122,\n",
       " 1815695,\n",
       " 1583159,\n",
       " 1564762,\n",
       " 976231,\n",
       " 1528719,\n",
       " 15814,\n",
       " 452942,\n",
       " 1298933,\n",
       " 1970282,\n",
       " 521080,\n",
       " 753237,\n",
       " 611238,\n",
       " 925017,\n",
       " 789163,\n",
       " 1539824,\n",
       " 393454,\n",
       " 1550696,\n",
       " 94644,\n",
       " 884966,\n",
       " 643688,\n",
       " 511511,\n",
       " 65226,\n",
       " 1422197,\n",
       " 412015,\n",
       " 536025,\n",
       " 105424,\n",
       " 1709256,\n",
       " 195352,\n",
       " 1083045,\n",
       " 796444,\n",
       " 702707,\n",
       " 1777003,\n",
       " 1204125,\n",
       " 664502,\n",
       " 199339,\n",
       " 793545,\n",
       " 488275,\n",
       " 1708781,\n",
       " 1223380,\n",
       " 1964249,\n",
       " 1054698,\n",
       " 458687,\n",
       " 309712,\n",
       " 1895630,\n",
       " 397384,\n",
       " 1056834,\n",
       " 1259482,\n",
       " 770885,\n",
       " 1796758,\n",
       " 1007786,\n",
       " 118676,\n",
       " 407517,\n",
       " 1243818,\n",
       " 468716,\n",
       " 1208470,\n",
       " 404822,\n",
       " 595805,\n",
       " 1168040,\n",
       " 1553593,\n",
       " 1504693,\n",
       " 635644,\n",
       " 1526657,\n",
       " 1428611,\n",
       " 1416615,\n",
       " 673736,\n",
       " 1879766,\n",
       " 32133,\n",
       " 57588,\n",
       " 357580,\n",
       " 1090885,\n",
       " 294297,\n",
       " 449738,\n",
       " 1946080,\n",
       " 964452,\n",
       " 1983951,\n",
       " 138782,\n",
       " 1310485,\n",
       " 162218,\n",
       " 1827969,\n",
       " 6846,\n",
       " 1279220,\n",
       " 1384935,\n",
       " 14897,\n",
       " 1330690,\n",
       " 1121833,\n",
       " 1123164,\n",
       " 1759573,\n",
       " 922832,\n",
       " 1295895,\n",
       " 1196188,\n",
       " 820674,\n",
       " 1437235,\n",
       " 1738419,\n",
       " 1584532,\n",
       " 715376,\n",
       " 531695,\n",
       " 179106,\n",
       " 356944,\n",
       " 1177719,\n",
       " 880397,\n",
       " 43745,\n",
       " 488371,\n",
       " 643876,\n",
       " 670157,\n",
       " 1983952,\n",
       " 576883,\n",
       " 1957675,\n",
       " 495301,\n",
       " 87417,\n",
       " 281573,\n",
       " 108060,\n",
       " 783535,\n",
       " 898189,\n",
       " 755825,\n",
       " 1442207,\n",
       " 901297,\n",
       " 134155,\n",
       " 509709,\n",
       " 981085,\n",
       " 712758,\n",
       " 809771,\n",
       " 322519,\n",
       " 79974,\n",
       " 136128,\n",
       " 1022107,\n",
       " 1123733,\n",
       " 587600,\n",
       " 11674,\n",
       " 1789901,\n",
       " 1047981,\n",
       " 1142273,\n",
       " 1215309,\n",
       " 458501,\n",
       " 683572,\n",
       " 1737305,\n",
       " 1948240,\n",
       " 993384,\n",
       " 24268,\n",
       " 781036,\n",
       " 1249268,\n",
       " 917476,\n",
       " 585645,\n",
       " 1583142,\n",
       " 1956247,\n",
       " 1121530,\n",
       " 1925624,\n",
       " 708243,\n",
       " 638106,\n",
       " 1943595,\n",
       " 1833751,\n",
       " 420669,\n",
       " 191427,\n",
       " 1958212,\n",
       " 1988172,\n",
       " 313134,\n",
       " 1178700,\n",
       " 913145,\n",
       " 1947702,\n",
       " 1259020,\n",
       " 31336,\n",
       " 167128,\n",
       " 1192450,\n",
       " 1182759,\n",
       " 1877444,\n",
       " 634507,\n",
       " 41365,\n",
       " 1629827,\n",
       " 65322,\n",
       " 1963844,\n",
       " 156314,\n",
       " 1046807,\n",
       " 523767,\n",
       " 519049,\n",
       " 1769462,\n",
       " 1143401,\n",
       " 1419279,\n",
       " 1288994,\n",
       " 1316319,\n",
       " 66897,\n",
       " 1939246,\n",
       " 1451801,\n",
       " 1147064,\n",
       " 1280409,\n",
       " 1304314,\n",
       " 951658,\n",
       " 1027935,\n",
       " 726727,\n",
       " 1426744,\n",
       " 125247,\n",
       " 306661,\n",
       " 1205783,\n",
       " 836184,\n",
       " 1675810,\n",
       " 342538,\n",
       " 1493219,\n",
       " 552358,\n",
       " 321784,\n",
       " 1688489,\n",
       " 1759350,\n",
       " 947394,\n",
       " 1120895,\n",
       " 257736,\n",
       " 872413,\n",
       " 1394394,\n",
       " 1499828,\n",
       " 809571,\n",
       " 945985,\n",
       " 1231939,\n",
       " 733149,\n",
       " 1220261,\n",
       " 1515140,\n",
       " 1775138,\n",
       " 756675,\n",
       " 337768,\n",
       " 1290190,\n",
       " 365616,\n",
       " 1516525,\n",
       " 149197,\n",
       " 1841418,\n",
       " 1483712,\n",
       " 646911,\n",
       " 621603,\n",
       " 725392,\n",
       " 463659,\n",
       " 1144945,\n",
       " 221514,\n",
       " 1008746,\n",
       " 1616046,\n",
       " 146457,\n",
       " 1879543,\n",
       " 349266,\n",
       " 353918,\n",
       " 1539114,\n",
       " 1252451,\n",
       " 360848,\n",
       " 4491,\n",
       " 1487423,\n",
       " 822016,\n",
       " 722669,\n",
       " 288000,\n",
       " 1705374,\n",
       " 1935990,\n",
       " 39342,\n",
       " 1465316,\n",
       " 343463,\n",
       " 139696,\n",
       " 527294,\n",
       " 572979,\n",
       " 1186438,\n",
       " 53735,\n",
       " 1754611,\n",
       " 1453945,\n",
       " 290459,\n",
       " 1858815,\n",
       " 1115631,\n",
       " 1608876,\n",
       " 654343,\n",
       " 1245284,\n",
       " 1195069,\n",
       " 1068324,\n",
       " 100160,\n",
       " 1026808,\n",
       " 1128454,\n",
       " 807056,\n",
       " 1264459,\n",
       " 558177,\n",
       " 179824,\n",
       " 1145031,\n",
       " 1241537,\n",
       " 218229,\n",
       " 1128545,\n",
       " 1569090,\n",
       " 279077,\n",
       " 1067838,\n",
       " 1499165,\n",
       " 459522,\n",
       " 1919928,\n",
       " 1857843,\n",
       " 246961,\n",
       " 39389,\n",
       " 1133360,\n",
       " ...]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T11:45:13.145748Z",
     "start_time": "2018-10-20T11:45:09.355511Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "model = make_model(len(NAMES.vocab),\n",
    "                   len(TRG_NAMES.vocab),\n",
    "                   device=DEVICE,\n",
    "                   emb_size=32,\n",
    "                   hidden_size=256,\n",
    "                   num_layers=1,\n",
    "                   dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T11:45:13.518097Z",
     "start_time": "2018-10-20T11:45:13.512033Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (rnn): GRU(32, 256, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): BahdanauAttention(\n",
       "      (key_layer): Linear(in_features=512, out_features=256, bias=False)\n",
       "      (query_layer): Linear(in_features=256, out_features=256, bias=False)\n",
       "      (energy_layer): Linear(in_features=256, out_features=1, bias=False)\n",
       "    )\n",
       "    (rnn): GRU(544, 256, batch_first=True, dropout=0.2)\n",
       "    (bridge): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (dropout_layer): Dropout(p=0.2)\n",
       "    (pre_output_layer): Linear(in_features=800, out_features=256, bias=False)\n",
       "  )\n",
       "  (src_embed): Embedding(76, 32)\n",
       "  (trg_embed): Embedding(77, 32)\n",
       "  (generator): Generator(\n",
       "    (proj): Linear(in_features=256, out_features=77, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:13:15.331511Z",
     "start_time": "2018-10-20T13:13:10.799250Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/proc_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:13:44.016647Z",
     "start_time": "2018-10-20T13:13:43.738220Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:37:12.698384Z",
     "start_time": "2018-10-20T13:37:12.429614Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_gts = train_df.loc[val_ids,'fullname_true'].values\n",
    "val_ors = train_df.loc[val_ids,'fullname'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:25:01.754012Z",
     "start_time": "2018-10-20T13:23:58.271737Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training the model\n",
      "Evaluating the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 389/389 [00:16<00:00, 24.12it/s]\n",
      "  0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 389/389 [00:47<00:00,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation perplexity: 1.063839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dev_perplexities,dev_preds = train(model,\n",
    "                                   num_epochs=1,\n",
    "                                   print_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:25:07.255987Z",
     "start_time": "2018-10-20T13:25:07.252090Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199107, 199110)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_preds),len(val_gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:27:15.146006Z",
     "start_time": "2018-10-20T13:27:14.947910Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "incorrect_idx = list(train_df[train_df.target==1].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:29:44.975396Z",
     "start_time": "2018-10-20T13:29:44.963119Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1763541,\n",
       " 361081,\n",
       " 1361399,\n",
       " 175491,\n",
       " 586990,\n",
       " 629776,\n",
       " 1448272,\n",
       " 1177837,\n",
       " 14087,\n",
       " 436394,\n",
       " 1058886,\n",
       " 634640,\n",
       " 1170735,\n",
       " 1238753,\n",
       " 1264272,\n",
       " 234061,\n",
       " 1367493,\n",
       " 1291992,\n",
       " 1208654,\n",
       " 1422147,\n",
       " 1980736,\n",
       " 221351,\n",
       " 1328396,\n",
       " 564979,\n",
       " 205771,\n",
       " 1895036,\n",
       " 704375,\n",
       " 1478253,\n",
       " 1799704,\n",
       " 1253527,\n",
       " 1127169,\n",
       " 1632428,\n",
       " 1896440,\n",
       " 1880670,\n",
       " 801157,\n",
       " 796851,\n",
       " 1797501,\n",
       " 1478725,\n",
       " 1102253,\n",
       " 952937,\n",
       " 912277,\n",
       " 1201027,\n",
       " 979721,\n",
       " 775371,\n",
       " 755955,\n",
       " 1439509,\n",
       " 100407,\n",
       " 88135,\n",
       " 1805274,\n",
       " 1519072,\n",
       " 1679208,\n",
       " 361042,\n",
       " 104203,\n",
       " 184267,\n",
       " 369433,\n",
       " 1713690,\n",
       " 1792137,\n",
       " 1017153,\n",
       " 1311293,\n",
       " 534,\n",
       " 768462,\n",
       " 407381,\n",
       " 417441,\n",
       " 68729,\n",
       " 324638,\n",
       " 64400,\n",
       " 1468633,\n",
       " 1245941,\n",
       " 1920579,\n",
       " 544855,\n",
       " 589843,\n",
       " 220441,\n",
       " 296686,\n",
       " 196222,\n",
       " 1247550,\n",
       " 1326348,\n",
       " 1583410,\n",
       " 1074569,\n",
       " 796533,\n",
       " 1688353,\n",
       " 1046654,\n",
       " 1552859,\n",
       " 409163,\n",
       " 675628,\n",
       " 1406371,\n",
       " 1640126,\n",
       " 624860,\n",
       " 1077734,\n",
       " 1966146,\n",
       " 567139,\n",
       " 56144,\n",
       " 364612,\n",
       " 1356885,\n",
       " 84280,\n",
       " 357177,\n",
       " 961406,\n",
       " 1153893,\n",
       " 1192598,\n",
       " 1450489,\n",
       " 1875393,\n",
       " 1107958,\n",
       " 1389221,\n",
       " 495972,\n",
       " 1272779,\n",
       " 1849306,\n",
       " 1022732,\n",
       " 6653,\n",
       " 1686546,\n",
       " 74471,\n",
       " 1388655,\n",
       " 709784,\n",
       " 1176397,\n",
       " 373666,\n",
       " 1239738,\n",
       " 968760,\n",
       " 1308668,\n",
       " 833241,\n",
       " 1929095,\n",
       " 295644,\n",
       " 1978849,\n",
       " 765795,\n",
       " 694974,\n",
       " 134502,\n",
       " 1571913,\n",
       " 251736,\n",
       " 1907360,\n",
       " 1099836,\n",
       " 345112,\n",
       " 1460678,\n",
       " 1543920,\n",
       " 362074,\n",
       " 1312259,\n",
       " 1920249,\n",
       " 689929,\n",
       " 737912,\n",
       " 304263,\n",
       " 1425864,\n",
       " 1085961,\n",
       " 484869,\n",
       " 1031362,\n",
       " 1343202,\n",
       " 1788238,\n",
       " 102120,\n",
       " 1826377,\n",
       " 1823424,\n",
       " 1940816,\n",
       " 524880,\n",
       " 1441143,\n",
       " 585761,\n",
       " 646197,\n",
       " 1751705,\n",
       " 1854937,\n",
       " 1914705,\n",
       " 103669,\n",
       " 1027770,\n",
       " 1211572,\n",
       " 1740394,\n",
       " 664361,\n",
       " 1699179,\n",
       " 96206,\n",
       " 1332931,\n",
       " 1055193,\n",
       " 592988,\n",
       " 1984660,\n",
       " 573178,\n",
       " 1650079,\n",
       " 438787,\n",
       " 1937342,\n",
       " 1638056,\n",
       " 1549631,\n",
       " 446253,\n",
       " 126802,\n",
       " 1348967,\n",
       " 1610732,\n",
       " 1630044,\n",
       " 1025378,\n",
       " 152675,\n",
       " 1917733,\n",
       " 62965,\n",
       " 331061,\n",
       " 1556120,\n",
       " 1466929,\n",
       " 713188,\n",
       " 290315,\n",
       " 627084,\n",
       " 839093,\n",
       " 1939189,\n",
       " 250972,\n",
       " 1648972,\n",
       " 365599,\n",
       " 1356976,\n",
       " 838251,\n",
       " 818040,\n",
       " 1425519,\n",
       " 1287,\n",
       " 327837,\n",
       " 883939,\n",
       " 590021,\n",
       " 400897,\n",
       " 1406737,\n",
       " 1802670,\n",
       " 1184423,\n",
       " 1100855,\n",
       " 576088,\n",
       " 137257,\n",
       " 50794,\n",
       " 1772253,\n",
       " 1150138,\n",
       " 1242281,\n",
       " 222468,\n",
       " 482451,\n",
       " 1676139,\n",
       " 1844656,\n",
       " 311426,\n",
       " 988151,\n",
       " 468130,\n",
       " 1642098,\n",
       " 173091,\n",
       " 1495697,\n",
       " 366621,\n",
       " 1577175,\n",
       " 512504,\n",
       " 12923,\n",
       " 574995,\n",
       " 1457800,\n",
       " 1140167,\n",
       " 795900,\n",
       " 1585648,\n",
       " 1658574,\n",
       " 1662973,\n",
       " 1066533,\n",
       " 626441,\n",
       " 564187,\n",
       " 1589515,\n",
       " 1831237,\n",
       " 1139147,\n",
       " 461723,\n",
       " 1978498,\n",
       " 4683,\n",
       " 1777988,\n",
       " 354074,\n",
       " 1171959,\n",
       " 369596,\n",
       " 446649,\n",
       " 422905,\n",
       " 749409,\n",
       " 474396,\n",
       " 1636163,\n",
       " 1418670,\n",
       " 1943000,\n",
       " 952654,\n",
       " 1092153,\n",
       " 582494,\n",
       " 1496777,\n",
       " 253485,\n",
       " 1976068,\n",
       " 635969,\n",
       " 127727,\n",
       " 1175444,\n",
       " 40388,\n",
       " 687620,\n",
       " 1101993,\n",
       " 753469,\n",
       " 1640969,\n",
       " 336688,\n",
       " 1249347,\n",
       " 713673,\n",
       " 1362462,\n",
       " 1478466,\n",
       " 874721,\n",
       " 1640833,\n",
       " 1801172,\n",
       " 1676576,\n",
       " 657102,\n",
       " 1210233,\n",
       " 1587955,\n",
       " 879244,\n",
       " 640497,\n",
       " 1029574,\n",
       " 1492706,\n",
       " 1685598,\n",
       " 1238228,\n",
       " 1789103,\n",
       " 522336,\n",
       " 13901,\n",
       " 1213737,\n",
       " 149001,\n",
       " 750484,\n",
       " 905069,\n",
       " 1831811,\n",
       " 1194,\n",
       " 36757,\n",
       " 1481518,\n",
       " 408838,\n",
       " 46831,\n",
       " 1742404,\n",
       " 1474946,\n",
       " 1161759,\n",
       " 721440,\n",
       " 193511,\n",
       " 1026724,\n",
       " 1701355,\n",
       " 1605264,\n",
       " 1093862,\n",
       " 213441,\n",
       " 228005,\n",
       " 1115443,\n",
       " 1054760,\n",
       " 254658,\n",
       " 638706,\n",
       " 36841,\n",
       " 954513,\n",
       " 1485696,\n",
       " 1761370,\n",
       " 1758848,\n",
       " 1909869,\n",
       " 694436,\n",
       " 1963045,\n",
       " 307365,\n",
       " 1224081,\n",
       " 122937,\n",
       " 1203554,\n",
       " 1347282,\n",
       " 477422,\n",
       " 1866146,\n",
       " 981090,\n",
       " 1678868,\n",
       " 586598,\n",
       " 716622,\n",
       " 997315,\n",
       " 657028,\n",
       " 1122898,\n",
       " 798834,\n",
       " 1098749,\n",
       " 218171,\n",
       " 430292,\n",
       " 1851924,\n",
       " 1345745,\n",
       " 1354535,\n",
       " 1581182,\n",
       " 1215159,\n",
       " 1934725,\n",
       " 1968338,\n",
       " 1037109,\n",
       " 970777,\n",
       " 113162,\n",
       " 1444282,\n",
       " 823573,\n",
       " 1811520,\n",
       " 1061223,\n",
       " 1555724,\n",
       " 1167680,\n",
       " 1254876,\n",
       " 780974,\n",
       " 617143,\n",
       " 244658,\n",
       " 629059,\n",
       " 43063,\n",
       " 139578,\n",
       " 1451487,\n",
       " 1590229,\n",
       " 1499965,\n",
       " 1946694,\n",
       " 1679434,\n",
       " 1076449,\n",
       " 1140061,\n",
       " 319452,\n",
       " 1036402,\n",
       " 1140687,\n",
       " 466813,\n",
       " 1550940,\n",
       " 8829,\n",
       " 603921,\n",
       " 12650,\n",
       " 248843,\n",
       " 409727,\n",
       " 49315,\n",
       " 1823123,\n",
       " 1275892,\n",
       " 1498369,\n",
       " 1322538,\n",
       " 1344529,\n",
       " 1304789,\n",
       " 1591067,\n",
       " 1049742,\n",
       " 28377,\n",
       " 1107872,\n",
       " 500853,\n",
       " 88205,\n",
       " 32053,\n",
       " 14691,\n",
       " 1120127,\n",
       " 1154689,\n",
       " 1390961,\n",
       " 1909863,\n",
       " 127503,\n",
       " 1292162,\n",
       " 665607,\n",
       " 1798039,\n",
       " 1777575,\n",
       " 1168940,\n",
       " 1179249,\n",
       " 1911090,\n",
       " 1849383,\n",
       " 469970,\n",
       " 355155,\n",
       " 638599,\n",
       " 507247,\n",
       " 1439816,\n",
       " 1828942,\n",
       " 1034013,\n",
       " 524279,\n",
       " 1655195,\n",
       " 92181,\n",
       " 1139260,\n",
       " 555810,\n",
       " 813807,\n",
       " 1910497,\n",
       " 404067,\n",
       " 1675757,\n",
       " 739967,\n",
       " 1327921,\n",
       " 1621577,\n",
       " 1549051,\n",
       " 1908792,\n",
       " 1338274,\n",
       " 817085,\n",
       " 1243338,\n",
       " 656415,\n",
       " 710131,\n",
       " 1529560,\n",
       " 1881332,\n",
       " 24738,\n",
       " 1960198,\n",
       " 255250,\n",
       " 245724,\n",
       " 1680302,\n",
       " 1752217,\n",
       " 756102,\n",
       " 873884,\n",
       " 450378,\n",
       " 1370950,\n",
       " 1577068,\n",
       " 1071122,\n",
       " 996208,\n",
       " 1191512,\n",
       " 338600,\n",
       " 727540,\n",
       " 587773,\n",
       " 1877781,\n",
       " 1436983,\n",
       " 1200839,\n",
       " 1103414,\n",
       " 1450130,\n",
       " 1430267,\n",
       " 1621159,\n",
       " 1032216,\n",
       " 476846,\n",
       " 14783,\n",
       " 1637024,\n",
       " 1113767,\n",
       " 898241,\n",
       " 198419,\n",
       " 1542466,\n",
       " 1164159,\n",
       " 871411,\n",
       " 1404578,\n",
       " 466049,\n",
       " 936662,\n",
       " 1878190,\n",
       " 1574871,\n",
       " 1549252,\n",
       " 1673979,\n",
       " 306142,\n",
       " 1901130,\n",
       " 1730489,\n",
       " 525306,\n",
       " 637747,\n",
       " 1215811,\n",
       " 1243454,\n",
       " 1583553,\n",
       " 935869,\n",
       " 15787,\n",
       " 317998,\n",
       " 1632295,\n",
       " 615637,\n",
       " 1814465,\n",
       " 1906248,\n",
       " 1574360,\n",
       " 1111679,\n",
       " 1046006,\n",
       " 741387,\n",
       " 798671,\n",
       " 1494509,\n",
       " 1134775,\n",
       " 11257,\n",
       " 1382552,\n",
       " 1433246,\n",
       " 1910041,\n",
       " 1790458,\n",
       " 904754,\n",
       " 1385799,\n",
       " 660310,\n",
       " 1928213,\n",
       " 1595533,\n",
       " 948293,\n",
       " 1788537,\n",
       " 997337,\n",
       " 930818,\n",
       " 661326,\n",
       " 1148050,\n",
       " 1146437,\n",
       " 1541071,\n",
       " 1205596,\n",
       " 691876,\n",
       " 535770,\n",
       " 1808793,\n",
       " 409275,\n",
       " 701772,\n",
       " 1548165,\n",
       " 1981893,\n",
       " 1374431,\n",
       " 1063719,\n",
       " 1483156,\n",
       " 1788337,\n",
       " 1868597,\n",
       " 1081934,\n",
       " 1699543,\n",
       " 1651789,\n",
       " 1160621,\n",
       " 921922,\n",
       " 357266,\n",
       " 610572,\n",
       " 676701,\n",
       " 1886250,\n",
       " 1148196,\n",
       " 1391644,\n",
       " 900173,\n",
       " 642628,\n",
       " 80251,\n",
       " 346910,\n",
       " 253514,\n",
       " 610402,\n",
       " 1635110,\n",
       " 493679,\n",
       " 21476,\n",
       " 1922089,\n",
       " 388715,\n",
       " 956973,\n",
       " 1573065,\n",
       " 50227,\n",
       " 261633,\n",
       " 578398,\n",
       " 1987379,\n",
       " 1953372,\n",
       " 1661877,\n",
       " 1074109,\n",
       " 144557,\n",
       " 240945,\n",
       " 902989,\n",
       " 589738,\n",
       " 1975253,\n",
       " 743648,\n",
       " 1984789,\n",
       " 1490357,\n",
       " 1493956,\n",
       " 250473,\n",
       " 1760300,\n",
       " 573754,\n",
       " 569776,\n",
       " 806751,\n",
       " 158960,\n",
       " 1520801,\n",
       " 790363,\n",
       " 1893325,\n",
       " 582831,\n",
       " 1663132,\n",
       " 1285577,\n",
       " 973374,\n",
       " 1081157,\n",
       " 904068,\n",
       " 1915109,\n",
       " 1068049,\n",
       " 35702,\n",
       " 1089309,\n",
       " 79611,\n",
       " 156406,\n",
       " 1118845,\n",
       " 407940,\n",
       " 1613984,\n",
       " 1566426,\n",
       " 1300368,\n",
       " 1344127,\n",
       " 783548,\n",
       " 833099,\n",
       " 1232467,\n",
       " 34768,\n",
       " 1026003,\n",
       " 1089662,\n",
       " 932370,\n",
       " 1378649,\n",
       " 323782,\n",
       " 272816,\n",
       " 635208,\n",
       " 326278,\n",
       " 922,\n",
       " 655689,\n",
       " 1977177,\n",
       " 1899783,\n",
       " 76634,\n",
       " 781088,\n",
       " 652027,\n",
       " 209175,\n",
       " 732376,\n",
       " 1131606,\n",
       " 1926166,\n",
       " 1697971,\n",
       " 1750907,\n",
       " 1187053,\n",
       " 664591,\n",
       " 1802789,\n",
       " 1277581,\n",
       " 595276,\n",
       " 1696079,\n",
       " 227659,\n",
       " 1600551,\n",
       " 325365,\n",
       " 1504786,\n",
       " 743780,\n",
       " 1861323,\n",
       " 151402,\n",
       " 1543146,\n",
       " 795805,\n",
       " 942616,\n",
       " 318562,\n",
       " 1347002,\n",
       " 593932,\n",
       " 330952,\n",
       " 482677,\n",
       " 1836496,\n",
       " 1514133,\n",
       " 968434,\n",
       " 1315819,\n",
       " 825480,\n",
       " 1415546,\n",
       " 1281417,\n",
       " 1004384,\n",
       " 1898448,\n",
       " 882375,\n",
       " 1436438,\n",
       " 411753,\n",
       " 995971,\n",
       " 1688346,\n",
       " 933470,\n",
       " 848917,\n",
       " 1575581,\n",
       " 872398,\n",
       " 945259,\n",
       " 502887,\n",
       " 461384,\n",
       " 947650,\n",
       " 1643949,\n",
       " 1124367,\n",
       " 1959743,\n",
       " 419427,\n",
       " 142359,\n",
       " 248591,\n",
       " 666680,\n",
       " 1251068,\n",
       " 871820,\n",
       " 1126047,\n",
       " 104262,\n",
       " 274086,\n",
       " 853748,\n",
       " 1842747,\n",
       " 1828265,\n",
       " 1392539,\n",
       " 895481,\n",
       " 1322709,\n",
       " 1258109,\n",
       " 1692353,\n",
       " 590133,\n",
       " 1512770,\n",
       " 385117,\n",
       " 189953,\n",
       " 990207,\n",
       " 1716294,\n",
       " 1586891,\n",
       " 808690,\n",
       " 561329,\n",
       " 1150592,\n",
       " 1662010,\n",
       " 853608,\n",
       " 998339,\n",
       " 936239,\n",
       " 1625017,\n",
       " 147711,\n",
       " 1852604,\n",
       " 236709,\n",
       " 852098,\n",
       " 134550,\n",
       " 928636,\n",
       " 1355427,\n",
       " 767176,\n",
       " 721475,\n",
       " 1572670,\n",
       " 953586,\n",
       " 1062492,\n",
       " 980350,\n",
       " 969942,\n",
       " 936931,\n",
       " 370342,\n",
       " 1770847,\n",
       " 729868,\n",
       " 1786371,\n",
       " 1516177,\n",
       " 788520,\n",
       " 1114469,\n",
       " 1878122,\n",
       " 1815695,\n",
       " 1583159,\n",
       " 1564762,\n",
       " 976231,\n",
       " 1528719,\n",
       " 15814,\n",
       " 452942,\n",
       " 1298933,\n",
       " 1970282,\n",
       " 521080,\n",
       " 753237,\n",
       " 611238,\n",
       " 925017,\n",
       " 789163,\n",
       " 1539824,\n",
       " 393454,\n",
       " 1550696,\n",
       " 94644,\n",
       " 884966,\n",
       " 643688,\n",
       " 511511,\n",
       " 65226,\n",
       " 1422197,\n",
       " 412015,\n",
       " 536025,\n",
       " 105424,\n",
       " 1709256,\n",
       " 195352,\n",
       " 1083045,\n",
       " 796444,\n",
       " 702707,\n",
       " 1777003,\n",
       " 1204125,\n",
       " 664502,\n",
       " 199339,\n",
       " 793545,\n",
       " 488275,\n",
       " 1708781,\n",
       " 1223380,\n",
       " 1964249,\n",
       " 1054698,\n",
       " 458687,\n",
       " 309712,\n",
       " 1895630,\n",
       " 397384,\n",
       " 1056834,\n",
       " 1259482,\n",
       " 770885,\n",
       " 1796758,\n",
       " 1007786,\n",
       " 118676,\n",
       " 407517,\n",
       " 1243818,\n",
       " 468716,\n",
       " 1208470,\n",
       " 404822,\n",
       " 595805,\n",
       " 1168040,\n",
       " 1553593,\n",
       " 1504693,\n",
       " 635644,\n",
       " 1526657,\n",
       " 1428611,\n",
       " 1416615,\n",
       " 673736,\n",
       " 1879766,\n",
       " 32133,\n",
       " 57588,\n",
       " 357580,\n",
       " 1090885,\n",
       " 294297,\n",
       " 449738,\n",
       " 1946080,\n",
       " 964452,\n",
       " 1983951,\n",
       " 138782,\n",
       " 1310485,\n",
       " 162218,\n",
       " 1827969,\n",
       " 6846,\n",
       " 1279220,\n",
       " 1384935,\n",
       " 14897,\n",
       " 1330690,\n",
       " 1121833,\n",
       " 1123164,\n",
       " 1759573,\n",
       " 922832,\n",
       " 1295895,\n",
       " 1196188,\n",
       " 820674,\n",
       " 1437235,\n",
       " 1738419,\n",
       " 1584532,\n",
       " 715376,\n",
       " 531695,\n",
       " 179106,\n",
       " 356944,\n",
       " 1177719,\n",
       " 880397,\n",
       " 43745,\n",
       " 488371,\n",
       " 643876,\n",
       " 670157,\n",
       " 1983952,\n",
       " 576883,\n",
       " 1957675,\n",
       " 495301,\n",
       " 87417,\n",
       " 281573,\n",
       " 108060,\n",
       " 783535,\n",
       " 898189,\n",
       " 755825,\n",
       " 1442207,\n",
       " 901297,\n",
       " 134155,\n",
       " 509709,\n",
       " 981085,\n",
       " 712758,\n",
       " 809771,\n",
       " 322519,\n",
       " 79974,\n",
       " 136128,\n",
       " 1022107,\n",
       " 1123733,\n",
       " 587600,\n",
       " 11674,\n",
       " 1789901,\n",
       " 1047981,\n",
       " 1142273,\n",
       " 1215309,\n",
       " 458501,\n",
       " 683572,\n",
       " 1737305,\n",
       " 1948240,\n",
       " 993384,\n",
       " 24268,\n",
       " 781036,\n",
       " 1249268,\n",
       " 917476,\n",
       " 585645,\n",
       " 1583142,\n",
       " 1956247,\n",
       " 1121530,\n",
       " 1925624,\n",
       " 708243,\n",
       " 638106,\n",
       " 1943595,\n",
       " 1833751,\n",
       " 420669,\n",
       " 191427,\n",
       " 1958212,\n",
       " 1988172,\n",
       " 313134,\n",
       " 1178700,\n",
       " 913145,\n",
       " 1947702,\n",
       " 1259020,\n",
       " 31336,\n",
       " 167128,\n",
       " 1192450,\n",
       " 1182759,\n",
       " 1877444,\n",
       " 634507,\n",
       " 41365,\n",
       " 1629827,\n",
       " 65322,\n",
       " 1963844,\n",
       " 156314,\n",
       " 1046807,\n",
       " 523767,\n",
       " 519049,\n",
       " 1769462,\n",
       " 1143401,\n",
       " 1419279,\n",
       " 1288994,\n",
       " 1316319,\n",
       " 66897,\n",
       " 1939246,\n",
       " 1451801,\n",
       " 1147064,\n",
       " 1280409,\n",
       " 1304314,\n",
       " 951658,\n",
       " 1027935,\n",
       " 726727,\n",
       " 1426744,\n",
       " 125247,\n",
       " 306661,\n",
       " 1205783,\n",
       " 836184,\n",
       " 1675810,\n",
       " 342538,\n",
       " 1493219,\n",
       " 552358,\n",
       " 321784,\n",
       " 1688489,\n",
       " 1759350,\n",
       " 947394,\n",
       " 1120895,\n",
       " 257736,\n",
       " 872413,\n",
       " 1394394,\n",
       " 1499828,\n",
       " 809571,\n",
       " 945985,\n",
       " 1231939,\n",
       " 733149,\n",
       " 1220261,\n",
       " 1515140,\n",
       " 1775138,\n",
       " 756675,\n",
       " 337768,\n",
       " 1290190,\n",
       " 365616,\n",
       " 1516525,\n",
       " 149197,\n",
       " 1841418,\n",
       " 1483712,\n",
       " 646911,\n",
       " 621603,\n",
       " 725392,\n",
       " 463659,\n",
       " 1144945,\n",
       " 221514,\n",
       " 1008746,\n",
       " 1616046,\n",
       " 146457,\n",
       " 1879543,\n",
       " 349266,\n",
       " 353918,\n",
       " 1539114,\n",
       " 1252451,\n",
       " 360848,\n",
       " 4491,\n",
       " 1487423,\n",
       " 822016,\n",
       " 722669,\n",
       " 288000,\n",
       " 1705374,\n",
       " 1935990,\n",
       " 39342,\n",
       " 1465316,\n",
       " 343463,\n",
       " 139696,\n",
       " 527294,\n",
       " 572979,\n",
       " 1186438,\n",
       " 53735,\n",
       " 1754611,\n",
       " 1453945,\n",
       " 290459,\n",
       " 1858815,\n",
       " 1115631,\n",
       " 1608876,\n",
       " 654343,\n",
       " 1245284,\n",
       " 1195069,\n",
       " 1068324,\n",
       " 100160,\n",
       " 1026808,\n",
       " 1128454,\n",
       " 807056,\n",
       " 1264459,\n",
       " 558177,\n",
       " 179824,\n",
       " 1145031,\n",
       " 1241537,\n",
       " 218229,\n",
       " 1128545,\n",
       " 1569090,\n",
       " 279077,\n",
       " 1067838,\n",
       " 1499165,\n",
       " 459522,\n",
       " 1919928,\n",
       " 1857843,\n",
       " 246961,\n",
       " 39389,\n",
       " 1133360,\n",
       " ...]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:32:41.241724Z",
     "start_time": "2018-10-20T13:32:41.236739Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1013371"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incorrect_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:34:28.206289Z",
     "start_time": "2018-10-20T13:34:28.047660Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s = list(set(val_ids).intersection(set(incorrect_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:35:32.937341Z",
     "start_time": "2018-10-20T13:35:32.926539Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122841"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:35:21.731863Z",
     "start_time": "2018-10-20T13:35:21.728077Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "786432"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:38:31.689254Z",
     "start_time": "2018-10-20T13:38:31.670981Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "  \n",
      "  \n",
      "\n",
      "\n",
      "  \n",
      "  \n",
      "  \n",
      "\n",
      "\n",
      "  \n",
      "  \n",
      "  \n",
      "\n",
      "\n",
      "  \n",
      "  \n",
      "  \n",
      "\n",
      "\n",
      " \n",
      " \n",
      " \n",
      "\n",
      "\n",
      "  \n",
      "  \n",
      "  \n",
      "\n",
      "\n",
      " \n",
      " \n",
      " \n",
      "\n",
      "\n",
      "  \n",
      "  \n",
      "  \n",
      "\n",
      "\n",
      "  \n",
      "  \n",
      "  \n",
      "\n",
      "\n",
      " \n",
      " \n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    idx = val_ids.index(s[np.random.randint(0,len(s))])\n",
    "    print(val_ors[idx])\n",
    "    print(val_gts[idx])\n",
    "    print(dev_preds[idx])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:18:33.296066Z",
     "start_time": "2018-10-20T13:18:33.292854Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BOICU OLGA'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T13:18:28.512399Z",
     "start_time": "2018-10-20T13:18:28.509010Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BOICU OLGA'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_perplexity(perplexities):\n",
    "    \"\"\"plot perplexities\"\"\"\n",
    "    plt.title(\"Perplexity per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Perplexity\")\n",
    "    plt.plot(perplexities)\n",
    "    \n",
    "plot_perplexity(dev_perplexities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Collect all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T09:33:15.161830Z",
     "start_time": "2018-10-21T09:33:13.900731Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n",
      "CUDA: True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%env CUDA_VISIBLE_DEVICES=2\n",
    "import os \n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext import data, datasets\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "from pytorch.encoder_decoder import make_model\n",
    "\n",
    "from pytorch.encoder_decoder_utils import (Batch,rebatch,\n",
    "                                           SimpleLossCompute,\n",
    "                                           cleaner,\n",
    "                                           tokenize,\n",
    "                                           greedy_decode_batch,\n",
    "                                           lookup_words,\n",
    "                                           run_epoch\n",
    "                                           )\n",
    "\n",
    "from pytorch.metrics import (score_task1,\n",
    "                             score_task2)\n",
    "\n",
    "# we will use CUDA if it is available\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE=torch.device('cuda:0') # or set to 'cpu'\n",
    "print(\"CUDA:\", USE_CUDA)\n",
    "print(DEVICE)\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "os.environ[\"USE_CUDA\"] = str(USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T09:34:06.593274Z",
     "start_time": "2018-10-21T09:33:15.461026Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "cns = train_df.country.value_counts()\n",
    "top_countries = list(cns[cns>100].index)\n",
    "        \n",
    "train_df['country'] = train_df['country'].apply(lambda x: x if x in top_countries else 'OTHER')\n",
    "train_df.loc[pd.isnull(train_df.fullname_true),\n",
    "             'fullname_true'] = train_df.loc[pd.isnull(train_df.fullname_true),\n",
    "                                             'fullname']\n",
    "\n",
    "test_df['country'] = test_df['country'].apply(lambda x: x if x in top_countries else 'OTHER')\n",
    "\n",
    "cn_dict = dict(zip(sorted(list(train_df['country'].unique())),\n",
    "                   range(train_df['country'].nunique())))\n",
    "\n",
    "train_df['country'] = train_df['country'].apply(lambda x: cn_dict[x])\n",
    "test_df['country'] = test_df['country'].apply(lambda x: cn_dict[x])\n",
    "# fake full name for consistency with boilerplate NMT code\n",
    "test_df['fullname_true'] = test_df['fullname']\n",
    "test_df['target'] = 0\n",
    "\n",
    "cols = ['id','fullname','fullname_true','target','country']\n",
    "train_df = train_df[cols].set_index('id')\n",
    "test_df = test_df[cols].set_index('id')\n",
    "\n",
    "train_df.to_csv('../data/proc_train.csv')\n",
    "test_df.to_csv('../data/proc_test.csv')\n",
    "\"\"\"\n",
    "\n",
    "UNK_TOKEN = \"!\"\n",
    "PAD_TOKEN = \"_\"    \n",
    "SOS_TOKEN = \"[\"\n",
    "EOS_TOKEN = \"]\"\n",
    "LOWER = False\n",
    "\n",
    "ID = data.Field(sequential=False,\n",
    "                use_vocab=False)\n",
    "\n",
    "NAMES = data.Field(tokenize=tokenize, \n",
    "                 batch_first=True,\n",
    "                 lower=LOWER,\n",
    "                 include_lengths=True,\n",
    "                 unk_token=UNK_TOKEN,\n",
    "                 pad_token=PAD_TOKEN,\n",
    "                 init_token=None,\n",
    "                 eos_token=EOS_TOKEN)\n",
    "\n",
    "TRG_NAMES = data.Field(tokenize=tokenize, \n",
    "                       batch_first=True,\n",
    "                       lower=LOWER,\n",
    "                       include_lengths=True,\n",
    "                       unk_token=UNK_TOKEN,\n",
    "                       pad_token=PAD_TOKEN,\n",
    "                       init_token=SOS_TOKEN,\n",
    "                       eos_token=EOS_TOKEN)\n",
    "\n",
    "LBL = data.Field(sequential=False,\n",
    "                 use_vocab=False)\n",
    "\n",
    "CNT = data.Field(sequential=False,\n",
    "                 use_vocab=False)\n",
    "\n",
    "datafields = [(\"id\", ID),\n",
    "              (\"src\", NAMES),\n",
    "              (\"trg\", TRG_NAMES),\n",
    "              (\"clf\", LBL),\n",
    "              (\"cn\", CNT)\n",
    "             ]\n",
    "\n",
    "train_data = data.TabularDataset(path=\"../data/proc_train.csv\",\n",
    "                                 format='csv',\n",
    "                                 skip_header=True,\n",
    "                                 fields=datafields)\n",
    "\n",
    "train_data, valid_data = train_data.split(split_ratio=0.9,\n",
    "                                          stratified=True,\n",
    "                                          strata_field='cn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T09:34:06.597695Z",
     "start_time": "2018-10-21T09:34:06.594871Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length 1791994, val length 199110\n"
     ]
    }
   ],
   "source": [
    "print('Train length {}, val length {}'.format(len(train_data),len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T09:34:06.605419Z",
     "start_time": "2018-10-21T09:34:06.599343Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T09:34:35.195955Z",
     "start_time": "2018-10-21T09:34:06.606885Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MIN_FREQ = 1  # NOTE: we limit the vocabulary to frequent words for speed\n",
    "NAMES.build_vocab(train_data.src, min_freq=MIN_FREQ)\n",
    "TRG_NAMES.build_vocab(train_data.trg, min_freq=MIN_FREQ)\n",
    "PAD_INDEX = TRG_NAMES.vocab.stoi[PAD_TOKEN]\n",
    "\n",
    "train_iter = data.BucketIterator(train_data,\n",
    "                                 batch_size=batch_size,\n",
    "                                 train=True, \n",
    "                                 sort_within_batch=True, \n",
    "                                 sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                                 repeat=False,\n",
    "                                 device=DEVICE,\n",
    "                                 shuffle=True)\n",
    "\n",
    "valid_iter_batch = data.Iterator(valid_data,\n",
    "                           batch_size=batch_size,\n",
    "                           train=False,\n",
    "                           sort_within_batch=True,\n",
    "                           sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                           repeat=False, \n",
    "                           device=DEVICE,\n",
    "                           shuffle=False)\n",
    "\n",
    "val_ids = []\n",
    "for b in valid_iter_batch:\n",
    "    val_ids.extend(list(b.id.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T09:35:52.169207Z",
     "start_time": "2018-10-21T09:34:35.197971Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making dictionaries\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/proc_train.csv')\n",
    "train_df = train_df.set_index('id')\n",
    "val_gts = train_df.loc[val_ids,'fullname_true'].values\n",
    "val_ors = train_df.loc[val_ids,'fullname'].values\n",
    "incorrect_idx = list(train_df[train_df.target==1].index.values)\n",
    "\n",
    "incorrect_val_ids = list(set(val_ids).intersection(set(incorrect_idx)))\n",
    "correct_val_ids = list(set(val_ids)-set(incorrect_val_ids))\n",
    "\n",
    "print('Making dictionaries')\n",
    "id2gt = dict(train_df['fullname_true'])\n",
    "id2clf_gt = dict(train_df['target'])\n",
    "\n",
    "val_gts = [id2gt[_] for _ in val_ids]\n",
    "val_clf_gts = [id2clf_gt[_] for _ in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T09:35:52.206403Z",
     "start_time": "2018-10-21T09:35:52.170640Z"
    },
    "code_folding": [
     0,
     76
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          num_epochs=10,\n",
    "          lr=3*1e-4,\n",
    "          print_every=100,\n",
    "          train_iter=train_iter,\n",
    "          valid_iter_batch=valid_iter_batch):\n",
    "    \"\"\"Train a model on IWSLT\"\"\"\n",
    "    \n",
    "    # optionally add label smoothing; see the Annotated Transformer\n",
    "    # criterion = nn.NLLLoss(reduce=, ignore_index=PAD_INDEX)\n",
    "    criterion = nn.NLLLoss(size_average=False, ignore_index=0)\n",
    "    clf_criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # dev_perplexities = []\n",
    "    # dev_preds = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "      \n",
    "        print(\"Epoch\", epoch)\n",
    "        print('Training the model')\n",
    "        model.train()\n",
    "        \n",
    "        \n",
    "        train_perplexity, train_clf_loss = run_epoch((rebatch(PAD_INDEX, b) for b in train_iter), \n",
    "                                                     model,\n",
    "                                                     SimpleLossCompute(model.generator,\n",
    "                                                                       criterion,clf_criterion,\n",
    "                                                                       optim),\n",
    "                                                     print_every=print_every,\n",
    "                                                     num_batches=len(train_iter),\n",
    "                                                     epoch_no=epoch)\n",
    "       \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print('Evaluating the model')\n",
    "            \"\"\"\n",
    "            print_examples((rebatch(PAD_INDEX, x) for x in valid_iter), \n",
    "                           model, n=10, src_vocab=NAMES.vocab, trg_vocab=TRG_NAMES.vocab)        \n",
    "            \"\"\"\n",
    "            dev_perplexity, dev_clf_loss = run_epoch((rebatch(PAD_INDEX, b) for b in valid_iter_batch), \n",
    "                                                     model, \n",
    "                                                     SimpleLossCompute(model.generator,\n",
    "                                                                       criterion, clf_criterion,\n",
    "                                                                       None),\n",
    "                                                     num_batches=len(valid_iter_batch),\n",
    "                                                     epoch_no=epoch)\n",
    "            \n",
    "\n",
    "            preds,clf_preds = predict((rebatch(PAD_INDEX, x) for x in valid_iter_batch),\n",
    "                                      model, max_len=70, src_vocab=NAMES.vocab, trg_vocab=TRG_NAMES.vocab,\n",
    "                                      num_batches=len(valid_iter_batch)) \n",
    "            \n",
    "            df_true = pd.DataFrame(\n",
    "                {'id': val_ids,\n",
    "                 'target': val_clf_gts,\n",
    "                 'fullname_true':val_gts\n",
    "                })\n",
    "            df_pred = pd.DataFrame(\n",
    "                {'id': val_ids,\n",
    "                 'target': clf_preds,\n",
    "                 'fullname_true':preds\n",
    "                })\n",
    "\n",
    "            score1 = score_task1(df_true, df_pred)\n",
    "            score2 = score_task2(df_true, df_pred)\n",
    "            \n",
    "            # dev_preds.extend(preds)\n",
    "            print(\"Validation CLF Loss: %f\" % dev_clf_loss)\n",
    "            print(\"Validation perplexity: %f\" % dev_perplexity)\n",
    "            print(\"Score 1 {} / Score 2 {}\".format(score1,score2))\n",
    "            # dev_perplexities.append(dev_perplexity)\n",
    "        \n",
    "    return dev_perplexity,dev_clf_loss,preds,clf_preds \n",
    "\n",
    "def predict(example_iter, model, max_len=100, \n",
    "            sos_index=1, \n",
    "            src_eos_index=None, \n",
    "            trg_eos_index=None, \n",
    "            src_vocab=None, trg_vocab=None,\n",
    "            num_batches=100):\n",
    "    \"\"\"Prints N examples. Assumes batch size of 1.\"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    print()\n",
    "    \n",
    "    if src_vocab is not None and trg_vocab is not None:\n",
    "        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n",
    "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
    "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
    "    else:\n",
    "        src_eos_index = None\n",
    "        trg_sos_index = 1\n",
    "        trg_eos_index = None\n",
    "\n",
    "    preds = []\n",
    "    clf_preds = []\n",
    "\n",
    "    with tqdm(total=num_batches) as pbar:\n",
    "        for i, batch in enumerate(example_iter):\n",
    "\n",
    "            output, pred_classes = greedy_decode_batch(\n",
    "                model, batch.src, batch.src_mask, batch.src_lengths,\n",
    "                max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index)\n",
    "\n",
    "            clf_preds.extend(list(pred_classes))\n",
    "            \n",
    "            # cut off everything starting from </s> \n",
    "            # (only when eos_index provided)\n",
    "            if trg_eos_index is not None:\n",
    "                # iterate over sentence predictions and cut off from eos\n",
    "                for pred in output:\n",
    "                    first_eos = np.where(pred==trg_eos_index)[0]\n",
    "                    if len(first_eos) > 0:\n",
    "                        # produce sentences\n",
    "                        preds.append(\"\".join(lookup_words(pred[:first_eos[0]],\n",
    "                                             vocab=TRG_NAMES.vocab)))\n",
    "                    else:\n",
    "                        preds.append(\"\".join(lookup_words(pred[:],\n",
    "                                             vocab=TRG_NAMES.vocab)))                        \n",
    "            pbar.update(1)\n",
    "    return preds,clf_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T08:21:55.799463Z",
     "start_time": "2018-10-21T08:12:34.568112Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 0: 100%|| 3500/3500 [08:15<00:00,  7.61it/s, clf_loss=(818.2644922015716, 19.23345375061035), loss=(67.82710825528588, 59.244354248046875), tkns_per_sec=1.08e+05]  \n",
      "  0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 0: 100%|| 389/389 [00:17<00:00, 22.78it/s]\n",
      "  0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 389/389 [00:48<00:00,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CLF Loss: 0.043791\n",
      "Validation perplexity: 7.664554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dev_perplexity,dev_clf_loss,(preds,clf_preds) = train(model,\n",
    "                                                      num_epochs=1,\n",
    "                                                      print_every=10,\n",
    "                                                      train_iter=train_iter,\n",
    "                                                      valid_iter_batch=valid_iter_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T08:59:37.884759Z",
     "start_time": "2018-10-21T08:28:55.887578Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 0: 100%|| 3500/3500 [09:03<00:00,  6.57it/s, clf_loss=(0.6807977768832063, 0.6317099928855896), loss=(6.216375645817579, 2.0935521125793457), tkns_per_sec=8.75e+04] \n",
      "  0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 0: 100%|| 389/389 [00:18<00:00, 11.30it/s]\n",
      "  0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 389/389 [00:50<00:00,  4.75it/s]\n",
      "  0%|          | 0/3500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CLF Loss: 0.001132\n",
      "Validation perplexity: 1.058362\n",
      "Score 1 0.7667157381329958 / Score 2 0.38132686849574265\n",
      "Epoch 1\n",
      "Training the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 1: 100%|| 3500/3500 [08:37<00:00,  6.72it/s, clf_loss=(0.47842981377899113, 0.32011860609054565), loss=(1.4579715156682316, 1.0631099939346313), tkns_per_sec=9.26e+04]\n",
      "  0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 1: 100%|| 389/389 [00:18<00:00, 21.11it/s]\n",
      "  0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 389/389 [00:50<00:00,  5.06it/s]\n",
      "  0%|          | 0/3500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CLF Loss: 0.000756\n",
      "Validation perplexity: 1.043601\n",
      "Score 1 0.8771369809476454 / Score 2 0.5331717123935666\n",
      "Epoch 2\n",
      "Training the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 2: 100%|| 3500/3500 [09:18<00:00,  3.70it/s, clf_loss=(0.34585219249018284, 0.24895672500133514), loss=(1.1533008893467753, 1.0529717206954956), tkns_per_sec=6.84e+04]\n",
      "  0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 2: 100%|| 389/389 [00:18<00:00, 11.76it/s]\n",
      "  0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 389/389 [00:49<00:00,  5.26it/s]\n",
      "  0%|          | 0/3500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CLF Loss: 0.000595\n",
      "Validation perplexity: 1.038028\n",
      "Score 1 0.9080623550321385 / Score 2 0.5886845632292652\n",
      "Epoch 3\n",
      "Training the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 3:   1%|          | 36/3500 [00:09<09:21,  6.17it/s, clf_loss=(0.3155379667878151, 0.386107861995697), loss=(1.1229129095872243, 1.2264965772628784), tkns_per_sec=8.43e+04]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-bcf25a450498>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                     \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                     \u001b[0mtrain_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                                     valid_iter_batch=valid_iter_batch)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-9bfe957b09c7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, num_epochs, lr, print_every, train_iter, valid_iter_batch)\u001b[0m\n\u001b[1;32m     31\u001b[0m                                                      \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                                      \u001b[0mnum_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                                                      epoch_no=epoch)\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebook/nvme/cft_name/src/pytorch/encoder_decoder_utils.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(data_iter, model, loss_compute, print_every, num_batches, epoch_no)\u001b[0m\n\u001b[1;32m    185\u001b[0m             loss, clf_loss = loss_compute(pre_output, batch.trg_y, batch.nseqs,\n\u001b[1;32m    186\u001b[0m                                           clf_logits,batch.clf)\n\u001b[0;32m--> 187\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mtotal_clf_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclf_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-7490d9dfbcfc>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, y, norm, clf_logits, clf_gts)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dev_perplexity,dev_clf_loss,preds,clf_preds = train(model,\n",
    "                                                    lr=3*1e-4,\n",
    "                                                    num_epochs=5,\n",
    "                                                    print_every=10,\n",
    "                                                    train_iter=train_iter,\n",
    "                                                    valid_iter_batch=valid_iter_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T09:30:48.052507Z",
     "start_time": "2018-10-21T09:00:40.324604Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "\r",
      "  0%|          | 0/3500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 0: 100%|| 3500/3500 [08:37<00:00,  5.61it/s, clf_loss=(0.5001867479475303, 0.38214975595474243), loss=(3.2625917642308297, 0.8913140296936035), tkns_per_sec=8.83e+04]\n",
      "  0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 0: 100%|| 389/389 [00:18<00:00, 11.50it/s]\n",
      "  0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 389/389 [00:50<00:00,  5.07it/s]\n",
      "  0%|          | 0/3500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CLF Loss: 0.000610\n",
      "Validation perplexity: 1.042382\n",
      "Score 1 0.9044932273002644 / Score 2 0.5750650425733207\n",
      "Epoch 1\n",
      "Training the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 1: 100%|| 3500/3500 [09:03<00:00,  6.44it/s, clf_loss=(0.2980027579883658, 0.23921769857406616), loss=(1.0948108145392728, 0.6816920042037964), tkns_per_sec=8.75e+04] \n",
      "  0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 1: 100%|| 389/389 [00:18<00:00, 11.75it/s]\n",
      "  0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 389/389 [00:50<00:00,  5.09it/s]\n",
      "  0%|          | 0/3500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CLF Loss: 0.000527\n",
      "Validation perplexity: 1.039240\n",
      "Score 1 0.9199550142959714 / Score 2 0.6021562598549354\n",
      "Epoch 2\n",
      "Training the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 2: 100%|| 3500/3500 [08:51<00:00,  6.94it/s, clf_loss=(0.25909127683316857, 0.27002274990081787), loss=(0.9336122642570477, 0.563675045967102), tkns_per_sec=9.85e+04] \n",
      "  0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 2: 100%|| 389/389 [00:17<00:00, 12.38it/s]\n",
      "  0%|          | 0/389 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 389/389 [00:51<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CLF Loss: 0.000467\n",
      "Validation perplexity: 1.031403\n",
      "Score 1 0.9317467091415024 / Score 2 0.6700863292336803\n"
     ]
    }
   ],
   "source": [
    "model = make_model(len(NAMES.vocab),\n",
    "                   len(TRG_NAMES.vocab),\n",
    "                   device=DEVICE,\n",
    "                   emb_size=300,\n",
    "                   hidden_size=256,\n",
    "                   num_layers=1,\n",
    "                   dropout=0.2,\n",
    "                   num_classes=3)\n",
    "\n",
    "dev_perplexity,dev_clf_loss,preds,clf_preds = train(model,\n",
    "                                                    lr=1*1e-3,\n",
    "                                                    num_epochs=3,\n",
    "                                                    print_every=10,\n",
    "                                                    train_iter=train_iter,\n",
    "                                                    valid_iter_batch=valid_iter_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T10:34:36.786241Z",
     "start_time": "2018-10-21T09:35:52.207855Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/7000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 0: 100%|| 7000/7000 [27:12<00:00,  4.80it/s, clf_loss=(0.39547945061116474, 0.49461132287979126), loss=(2.0592107862263687, 0.9965192079544067), tkns_per_sec=2.98e+04]\n",
      "  0%|          | 0/778 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 0: 100%|| 778/778 [00:49<00:00, 15.72it/s]\n",
      "  0%|          | 0/778 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 778/778 [02:23<00:00,  3.75it/s]\n",
      "  0%|          | 0/7000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CLF Loss: 0.001204\n",
      "Validation perplexity: 1.038273\n",
      "Score 1 0.9123998757031274 / Score 2 0.6456681234797398\n",
      "Epoch 1\n",
      "Training the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 1: 100%|| 7000/7000 [27:14<00:00,  4.29it/s, clf_loss=(0.28426167526645446, 0.2397373914718628), loss=(1.1064933041929867, 1.405472993850708), tkns_per_sec=2.88e+04]   \n",
      "  0%|          | 0/778 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 1: 100%|| 778/778 [00:50<00:00, 15.39it/s]\n",
      "  0%|          | 0/778 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 83/778 [00:12<01:46,  6.53it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1b0e54f48add>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                                                     \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                     \u001b[0mtrain_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                                     valid_iter_batch=valid_iter_batch)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-9bfe957b09c7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, num_epochs, lr, print_every, train_iter, valid_iter_batch)\u001b[0m\n\u001b[1;32m     51\u001b[0m             preds,clf_preds = predict((rebatch(PAD_INDEX, x) for x in valid_iter_batch),\n\u001b[1;32m     52\u001b[0m                                       \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNAMES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRG_NAMES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                                       num_batches=len(valid_iter_batch)) \n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             df_true = pd.DataFrame(\n",
      "\u001b[0;32m<ipython-input-7-9bfe957b09c7>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(example_iter, model, max_len, sos_index, src_eos_index, trg_eos_index, src_vocab, trg_vocab, num_batches)\u001b[0m\n\u001b[1;32m    104\u001b[0m             output, pred_classes = greedy_decode_batch(\n\u001b[1;32m    105\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mclf_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebook/nvme/cft_name/src/pytorch/encoder_decoder_utils.py\u001b[0m in \u001b[0;36mgreedy_decode_batch\u001b[0;34m(model, src, src_mask, src_lengths, max_len, sos_index, eos_index)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mnext_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mprev_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# attention_scores.append(model.decoder.attention.alphas.cpu().numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = make_model(len(NAMES.vocab),\n",
    "                   len(TRG_NAMES.vocab),\n",
    "                   device=DEVICE,\n",
    "                   emb_size=512,\n",
    "                   hidden_size=512,\n",
    "                   num_layers=2,\n",
    "                   dropout=0.2,\n",
    "                   num_classes=3)\n",
    "\n",
    "dev_perplexity,dev_clf_loss,preds,clf_preds = train(model,\n",
    "                                                    lr=1*1e-3,\n",
    "                                                    num_epochs=3,\n",
    "                                                    print_every=10,\n",
    "                                                    train_iter=train_iter,\n",
    "                                                    valid_iter_batch=valid_iter_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T08:22:08.035182Z",
     "start_time": "2018-10-21T08:22:08.023516Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199110, 199110)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds),len(clf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T08:22:08.786020Z",
     "start_time": "2018-10-21T08:22:08.781678Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199110"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dataset pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T03:33:59.080147Z",
     "start_time": "2018-10-23T03:33:45.334776Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from torchtext import data, datasets\n",
    "\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "cns = train_df.country.value_counts()\n",
    "top_countries = list(cns[cns>100].index)\n",
    "        \n",
    "train_df['country'] = train_df['country'].apply(lambda x: x if x in top_countries else 'OTHER')\n",
    "train_df.loc[pd.isnull(train_df.fullname_true),\n",
    "             'fullname_true'] = train_df.loc[pd.isnull(train_df.fullname_true),\n",
    "                                             'fullname']\n",
    "\n",
    "test_df['country'] = test_df['country'].apply(lambda x: x if x in top_countries else 'OTHER')\n",
    "\n",
    "cn_dict = dict(zip(sorted(list(train_df['country'].unique())),\n",
    "                   range(train_df['country'].nunique())))\n",
    "\n",
    "train_df['country'] = train_df['country'].apply(lambda x: cn_dict[x])\n",
    "test_df['country'] = test_df['country'].apply(lambda x: cn_dict[x])\n",
    "# fake full name for consistency with boilerplate NMT code\n",
    "test_df['fullname_true'] = test_df['fullname']\n",
    "test_df['target'] = 0\n",
    "\n",
    "cols = ['id','fullname','fullname_true','target','country']\n",
    "train_df = train_df[cols].set_index('id')\n",
    "test_df = test_df[cols].set_index('id')\n",
    "\n",
    "# train_df.to_csv('../data/proc_train.csv')\n",
    "# test_df.to_csv('../data/proc_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T03:33:59.096371Z",
     "start_time": "2018-10-23T03:33:59.082206Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cn_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T16:19:22.938494Z",
     "start_time": "2018-10-22T16:19:22.659560Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T16:20:18.930261Z",
     "start_time": "2018-10-22T16:20:13.182261Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/proc_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T16:19:43.532691Z",
     "start_time": "2018-10-22T16:19:35.613332Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/proc_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T16:20:25.594980Z",
     "start_time": "2018-10-22T16:20:25.584652Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fullname</th>\n",
       "      <th>fullname_true</th>\n",
       "      <th>target</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AKHMEDOV YGURIY</td>\n",
       "      <td>AKHMEDOV YURIY</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                           fullname                     fullname_true  \\\n",
       "0   0                    AKHMEDOV YGURIY                    AKHMEDOV YURIY   \n",
       "1   1                               \n",
       "2   2                    \n",
       "3   3           \n",
       "4   4                  \n",
       "\n",
       "   target  country  \n",
       "0       1       44  \n",
       "1       1       44  \n",
       "2       0       44  \n",
       "3       1       44  \n",
       "4       0       44  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T16:19:43.598451Z",
     "start_time": "2018-10-22T16:19:43.534261Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fullname</th>\n",
       "      <th>fullname_true</th>\n",
       "      <th>target</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>OROSUMEBTOV MIRLAN</td>\n",
       "      <td>OROSUMEBTOV MIRLAN</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                        fullname                   fullname_true  target  \\\n",
       "0   0               0   \n",
       "1   1                             0   \n",
       "2   2                           0   \n",
       "3   3                 0   \n",
       "4   4              OROSUMEBTOV MIRLAN              OROSUMEBTOV MIRLAN       0   \n",
       "\n",
       "   country  \n",
       "0       51  \n",
       "1       44  \n",
       "2       51  \n",
       "3       28  \n",
       "4       44  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T18:41:56.522686Z",
     "start_time": "2018-11-11T18:41:56.166497Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def argmax(string):\n",
    "    arr = np.asarray(string.replace('[','')\n",
    "                     .replace(']','')\n",
    "                     .strip()\n",
    "                     .replace('  ',' ').replace('  ',' ').replace('  ',' ').split())\n",
    "    return np.argmax(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T18:42:17.562609Z",
     "start_time": "2018-11-11T18:42:17.314705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4.7G\r\n",
      "drwxr-xr-x 13 keras users 4.0K Nov 11 18:42 ..\r\n",
      "-rw-r--r--  1 root  root  248M Nov 11 18:00 aug2_pseudo5x_final2.csv\r\n",
      "drwxr-xr-x  2 keras users 4.0K Nov 11 18:00 .\r\n",
      "-rw-r--r--  1 root  root  247M Nov 11 18:00 train_aug_correct_only_final2.csv\r\n",
      "-rw-r--r--  1 root  root  432M Nov 10 07:29 aug2_pseudo_06_final2.csv\r\n",
      "-rw-r--r--  1 keras users  98M Nov 10 06:36 stack_v4.csv\r\n",
      "-rw-r--r--  1 root  root  248M Nov  8 12:48 aug2_pseudo_06_final.csv\r\n",
      "-rw-r--r--  1 root  root  244M Nov  8 11:49 heavy_dec_skip_final.csv\r\n",
      "-rw-r--r--  1 root  root  248M Nov  7 06:06 aug2_pseudo_06.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -laht predictions/ | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T18:45:12.912137Z",
     "start_time": "2018-11-11T18:44:14.464719Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/test.csv')\n",
    "predict_df = pd.read_csv('predictions/train_aug_correct_only_final2.csv')\n",
    "predict_df = predict_df.sort_values(by='id',ascending=True).reset_index(drop=True)\n",
    "test_df = test_df.sort_values(by='id',ascending=True).reset_index(drop=True)\n",
    "assert list(predict_df.id.values) == list(test_df.id.values)\n",
    "predict_df['target'] = predict_df['target'].apply(lambda x: argmax(x))\n",
    "predict_df['fullname'] = test_df['fullname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T18:45:21.661150Z",
     "start_time": "2018-11-11T18:45:17.818327Z"
    }
   },
   "outputs": [],
   "source": [
    "# assume that target = 2 is predicted correctly\n",
    "# use the seq2seq prediction as a stronger indicator for targets 0 and 1\n",
    "cond_0 = (predict_df.fullname_true == predict_df.fullname) & (predict_df.target.isin([0,1]))\n",
    "cond_1 = (predict_df.fullname_true != predict_df.fullname) & (predict_df.target.isin([0,1]))\n",
    "predict_df.loc[cond_0,'target'] = 0\n",
    "predict_df.loc[cond_1,'target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T18:46:25.364815Z",
     "start_time": "2018-11-11T18:46:13.458886Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_df.loc[predict_df.target!=1,'fullname_true'] = ''\n",
    "del predict_df['fullname']\n",
    "predict_df = predict_df.set_index('id')\n",
    "predict_df.to_csv('predictions/av_submit_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T18:46:30.478684Z",
     "start_time": "2018-11-11T18:46:30.459443Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>fullname_true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>OROSUMBETOV MIRLAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>- </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>MURATOV ELDOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>GULIYEV KHALID QABIL OGLU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>ALIYEV XASAY SALMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767609</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767610</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767611</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767612</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767613</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767614</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767615</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767616</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767617</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767618</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767619</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767620</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767621</th>\n",
       "      <td>1</td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767622</th>\n",
       "      <td>1</td>\n",
       "      <td>   </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767623</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767624</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767625</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767626</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767627</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767628</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767629</th>\n",
       "      <td>1</td>\n",
       "      <td>KHUJAMOV FARKHAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767630</th>\n",
       "      <td>1</td>\n",
       "      <td>   </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767631</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767632</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767633</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767634</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767635</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767636</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767637</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767638</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2767639 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                     fullname_true\n",
       "id                                               \n",
       "0             1       \n",
       "1             2                                  \n",
       "2             0                                  \n",
       "3             0                                  \n",
       "4             1                OROSUMBETOV MIRLAN\n",
       "5             2                                  \n",
       "6             1               \n",
       "7             1        \n",
       "8             1           \n",
       "9             1    \n",
       "10            1            - \n",
       "11            1       \n",
       "12            0                                  \n",
       "13            1                     MURATOV ELDOR\n",
       "14            1         GULIYEV KHALID QABIL OGLU\n",
       "15            0                                  \n",
       "16            0                                  \n",
       "17            0                                  \n",
       "18            1           \n",
       "19            0                                  \n",
       "20            0                                  \n",
       "21            1           \n",
       "22            1          \n",
       "23            0                                  \n",
       "24            1               ALIYEV XASAY SALMAN\n",
       "25            1            \n",
       "26            0                                  \n",
       "27            1          \n",
       "28            1            \n",
       "29            1       \n",
       "...         ...                               ...\n",
       "2767609       1             \n",
       "2767610       0                                  \n",
       "2767611       1    \n",
       "2767612       0                                  \n",
       "2767613       2                                  \n",
       "2767614       1             \n",
       "2767615       0                                  \n",
       "2767616       0                                  \n",
       "2767617       1          \n",
       "2767618       0                                  \n",
       "2767619       1     \n",
       "2767620       0                                  \n",
       "2767621       1             \n",
       "2767622       1            \n",
       "2767623       1          \n",
       "2767624       0                                  \n",
       "2767625       1             \n",
       "2767626       0                                  \n",
       "2767627       0                                  \n",
       "2767628       2                                  \n",
       "2767629       1                  KHUJAMOV FARKHAD\n",
       "2767630       1           \n",
       "2767631       0                                  \n",
       "2767632       0                                  \n",
       "2767633       0                                  \n",
       "2767634       0                                  \n",
       "2767635       0                                  \n",
       "2767636       0                                  \n",
       "2767637       1        \n",
       "2767638       1       \n",
       "\n",
       "[2767639 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T05:51:11.680970Z",
     "start_time": "2018-11-01T05:51:10.969890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>fullname_true</th>\n",
       "      <th>fullname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1773338</th>\n",
       "      <td>1773338</td>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815704</th>\n",
       "      <td>1815704</td>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541918</th>\n",
       "      <td>541918</td>\n",
       "      <td>2</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563592</th>\n",
       "      <td>563592</td>\n",
       "      <td>2</td>\n",
       "      <td>     -  -</td>\n",
       "      <td>     -  -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422502</th>\n",
       "      <td>1422502</td>\n",
       "      <td>2</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969686</th>\n",
       "      <td>1969686</td>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576973</th>\n",
       "      <td>1576973</td>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830829</th>\n",
       "      <td>1830829</td>\n",
       "      <td>2</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603386</th>\n",
       "      <td>603386</td>\n",
       "      <td>2</td>\n",
       "      <td>  RUSU</td>\n",
       "      <td>  RUSU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349937</th>\n",
       "      <td>2349937</td>\n",
       "      <td>2</td>\n",
       "      <td>VARDANYAN FEVIN</td>\n",
       "      <td>VARDANYANH FDVIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309693</th>\n",
       "      <td>2309693</td>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721911</th>\n",
       "      <td>721911</td>\n",
       "      <td>2</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457230</th>\n",
       "      <td>1457230</td>\n",
       "      <td>2</td>\n",
       "      <td> </td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753467</th>\n",
       "      <td>753467</td>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080206</th>\n",
       "      <td>2080206</td>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989629</th>\n",
       "      <td>989629</td>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972214</th>\n",
       "      <td>1972214</td>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914803</th>\n",
       "      <td>914803</td>\n",
       "      <td>2</td>\n",
       "      <td> </td>\n",
       "      <td> ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645965</th>\n",
       "      <td>2645965</td>\n",
       "      <td>2</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486387</th>\n",
       "      <td>486387</td>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  target                                fullname_true  \\\n",
       "1773338  1773338       2               \n",
       "1815704  1815704       2                         \n",
       "541918    541918       2                                  \n",
       "563592    563592       2          -  -   \n",
       "1422502  1422502       2                                \n",
       "1969686  1969686       2               \n",
       "1576973  1576973       2                            \n",
       "1830829  1830829       2                                       \n",
       "603386    603386       2                     RUSU   \n",
       "2349937  2349937       2                              VARDANYAN FEVIN   \n",
       "2309693  2309693       2                   \n",
       "721911    721911       2            \n",
       "1457230  1457230       2                                  \n",
       "753467    753467       2                               \n",
       "2080206  2080206       2                            \n",
       "989629    989629       2                           \n",
       "1972214  1972214       2                           \n",
       "914803    914803       2      \n",
       "2645965  2645965       2             \n",
       "486387    486387       2                            \n",
       "\n",
       "                                                  fullname  \n",
       "1773338                    \n",
       "1815704                               \n",
       "541918                                       \n",
       "563592                -  -  \n",
       "1422502                                    \n",
       "1969686                    \n",
       "1576973                                 \n",
       "1830829                                            \n",
       "603386                           RUSU  \n",
       "2349937                                   VARDANYANH FDVIN  \n",
       "2309693                       \n",
       "721911                    \n",
       "1457230                                       \n",
       "753467                                      \n",
       "2080206                                 \n",
       "989629                                 \n",
       "1972214                                \n",
       "914803    ...  \n",
       "2645965                \n",
       "486387                                  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df[(predict_df.fullname_true != predict_df.fullname)\\\n",
    "           & (predict_df.target==2)].sample(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T05:50:02.053974Z",
     "start_time": "2018-11-01T05:50:01.268840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1463831\n",
       "2        640\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df[predict_df.fullname_true != predict_df.fullname].target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T05:50:11.867664Z",
     "start_time": "2018-11-01T05:50:11.821402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1463831\n",
       "0    1242591\n",
       "2      61217\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T09:47:35.304343Z",
     "start_time": "2018-10-24T09:47:35.300319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.039187258735160775"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(35102+31228)/1692642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T10:02:25.491936Z",
     "start_time": "2018-10-24T10:02:24.877596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1618214\n",
       "2      31228\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond = predict_df.fullname_true != predict_df.fullname\n",
    "predict_df[cond].target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T09:03:39.657976Z",
     "start_time": "2018-10-27T09:03:39.511667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>fullname_true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980044</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172352</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412760</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002881</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002626</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399433</th>\n",
       "      <td>1</td>\n",
       "      <td>SOTIVOLDIYEVA OZODA ZOKIRJANOVNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914582</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671044</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754741</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390815</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689006</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449184</th>\n",
       "      <td>1</td>\n",
       "      <td>   </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379635</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523771</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191824</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208490</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104610</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934264</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256841</th>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                       fullname_true\n",
       "id                                                 \n",
       "1980044       1         \n",
       "172352        1         \n",
       "1412760       1           \n",
       "1002881       1    \n",
       "2002626       1             \n",
       "2399433       1    SOTIVOLDIYEVA OZODA ZOKIRJANOVNA\n",
       "525           1               \n",
       "1914582       1              \n",
       "1671044       1            \n",
       "754741        1           \n",
       "390815        1                \n",
       "689006        1          \n",
       "2449184       1                \n",
       "1379635       1          \n",
       "2523771       1              \n",
       "2191824       1             \n",
       "208490        1           \n",
       "1104610       1          \n",
       "934264        1             \n",
       "1256841       1       "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond = (predict_df.target==1)\n",
    "predict_df[cond].sample(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T09:00:55.762060Z",
     "start_time": "2018-10-27T09:00:54.977963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>fullname_true</th>\n",
       "      <th>fullname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>660373</th>\n",
       "      <td>660373</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077082</th>\n",
       "      <td>2077082</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427133</th>\n",
       "      <td>2427133</td>\n",
       "      <td>1</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371930</th>\n",
       "      <td>371930</td>\n",
       "      <td>1</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349480</th>\n",
       "      <td>2349480</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703051</th>\n",
       "      <td>2703051</td>\n",
       "      <td>1</td>\n",
       "      <td>KAMALKHANOV MUZAFFAR MAXMUD OGLI</td>\n",
       "      <td>KAMALKBHANOV MUZAFFAR MAXMUD OGLI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105819</th>\n",
       "      <td>2105819</td>\n",
       "      <td>1</td>\n",
       "      <td>HASANOV ANAR</td>\n",
       "      <td>HASANOV AQNAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721383</th>\n",
       "      <td>2721383</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243832</th>\n",
       "      <td>243832</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992750</th>\n",
       "      <td>992750</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462507</th>\n",
       "      <td>2462507</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>'  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723734</th>\n",
       "      <td>1723734</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974845</th>\n",
       "      <td>1974845</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436902</th>\n",
       "      <td>2436902</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464863</th>\n",
       "      <td>2464863</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400656</th>\n",
       "      <td>2400656</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794432</th>\n",
       "      <td>794432</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641177</th>\n",
       "      <td>2641177</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td> - </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191568</th>\n",
       "      <td>1191568</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847690</th>\n",
       "      <td>847690</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  target                      fullname_true  \\\n",
       "660373    660373       1         \n",
       "2077082  2077082       1              \n",
       "2427133  2427133       1                      \n",
       "371930    371930       1                       \n",
       "2349480  2349480       1               \n",
       "2703051  2703051       1   KAMALKHANOV MUZAFFAR MAXMUD OGLI   \n",
       "2105819  2105819       1                       HASANOV ANAR   \n",
       "2721383  2721383       1                 \n",
       "243832    243832       1                \n",
       "992750    992750       1             \n",
       "2462507  2462507       1         \n",
       "1723734  1723734       1       \n",
       "1974845  1974845       1             \n",
       "2436902  2436902       1                   \n",
       "2464863  2464863       1               \n",
       "2400656  2400656       1          \n",
       "794432    794432       1           \n",
       "2641177  2641177       1              \n",
       "1191568  1191568       1                 \n",
       "847690    847690       1                   \n",
       "\n",
       "                                  fullname  \n",
       "660373         \n",
       "2077082            \n",
       "2427133                     \n",
       "371930                      \n",
       "2349480              \n",
       "2703051  KAMALKBHANOV MUZAFFAR MAXMUD OGLI  \n",
       "2105819                      HASANOV AQNAR  \n",
       "2721383               \n",
       "243832                \n",
       "992750            \n",
       "2462507   '    \n",
       "1723734      \n",
       "1974845           \n",
       "2436902                 \n",
       "2464863             \n",
       "2400656         \n",
       "794432            \n",
       "2641177          -   \n",
       "1191568                \n",
       "847690                    "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond = (predict_df.fullname_true != predict_df.fullname) & (predict_df.target==1)\n",
    "predict_df[cond].sample(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T07:08:09.932352Z",
     "start_time": "2018-10-24T07:08:09.354561Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T07:09:41.258326Z",
     "start_time": "2018-10-24T07:09:33.612705Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T06:32:02.552610Z",
     "start_time": "2018-10-24T06:32:02.543998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fullname</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>  </td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td> </td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>  </td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>OROSUMEBTOV MIRLAN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                        fullname     country\n",
       "0   0      \n",
       "1   1                 \n",
       "2   2            \n",
       "3   3        \n",
       "4   4              OROSUMEBTOV MIRLAN      "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T09:43:07.213049Z",
     "start_time": "2018-10-24T09:43:07.153864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1692642\n",
       "0    1009353\n",
       "2      65644\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T09:41:58.746955Z",
     "start_time": "2018-10-24T09:41:58.726008Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>fullname_true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>ZHUSUPBEKOVA NUIA </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2</td>\n",
       "      <td>R  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2</td>\n",
       "      <td>  R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>2</td>\n",
       "      <td>RRR RR RR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>2</td>\n",
       "      <td>  NATALYA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>2</td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>2</td>\n",
       "      <td> - </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>2</td>\n",
       "      <td>R--  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>2</td>\n",
       "      <td>  R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>2</td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>2</td>\n",
       "      <td>SEVGEYEVICH  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>2</td>\n",
       "      <td>R  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>2</td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>2</td>\n",
       "      <td>MAVJUDA R </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766608</th>\n",
       "      <td>2</td>\n",
       "      <td> R </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766642</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766687</th>\n",
       "      <td>2</td>\n",
       "      <td>  ISMOILOV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766748</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766759</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766825</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766883</th>\n",
       "      <td>2</td>\n",
       "      <td>YEGHIAZAYAN  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766905</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766963</th>\n",
       "      <td>2</td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766972</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767055</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767061</th>\n",
       "      <td>2</td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767084</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767110</th>\n",
       "      <td>2</td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767144</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767151</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767255</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767298</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767322</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767348</th>\n",
       "      <td>2</td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767361</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767367</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767374</th>\n",
       "      <td>2</td>\n",
       "      <td>  -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767406</th>\n",
       "      <td>2</td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767429</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767483</th>\n",
       "      <td>2</td>\n",
       "      <td> R </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767549</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767595</th>\n",
       "      <td>2</td>\n",
       "      <td>TABACAI POITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767613</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767628</th>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65644 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                               fullname_true\n",
       "id                                                         \n",
       "1             2                       \n",
       "5             2               \n",
       "38            2                      ZHUSUPBEKOVA NUIA \n",
       "80            2       R  \n",
       "193           2           R\n",
       "363           2                      \n",
       "408           2           \n",
       "431           2                    RRR RR RR\n",
       "460           2                      \n",
       "520           2                          \n",
       "548           2                NATALYA\n",
       "567           2                    \n",
       "614           2                             \n",
       "634           2           \n",
       "804           2                          \n",
       "807           2          \n",
       "876           2         - \n",
       "974           2    \n",
       "980           2                \n",
       "1047          2                   R--  \n",
       "1215          2        \n",
       "1252          2                      \n",
       "1277          2                 R\n",
       "1339          2                         \n",
       "1362          2                          \n",
       "1379          2                SEVGEYEVICH  \n",
       "1418          2               R  \n",
       "1433          2                 \n",
       "1595          2                MAVJUDA R \n",
       "1692          2                  \n",
       "...         ...                                         ...\n",
       "2766608       2                  R \n",
       "2766642       2                            \n",
       "2766687       2                   ISMOILOV\n",
       "2766748       2           \n",
       "2766759       2                \n",
       "2766825       2                \n",
       "2766883       2             YEGHIAZAYAN  \n",
       "2766905       2                           \n",
       "2766963       2                       \n",
       "2766972       2        \n",
       "2767055       2          \n",
       "2767061       2                          \n",
       "2767084       2                   \n",
       "2767110       2              \n",
       "2767144       2                \n",
       "2767151       2     \n",
       "2767255       2                        \n",
       "2767298       2                \n",
       "2767322       2                              \n",
       "2767348       2                       \n",
       "2767361       2                          \n",
       "2767367       2              \n",
       "2767374       2            -\n",
       "2767406       2                        \n",
       "2767429       2                      \n",
       "2767483       2            R \n",
       "2767549       2                    \n",
       "2767595       2                              TABACAI POITA\n",
       "2767613       2                     \n",
       "2767628       2               \n",
       "\n",
       "[65644 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df[predict_df.target==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T06:31:34.801993Z",
     "start_time": "2018-10-24T06:31:33.490924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>fullname_true</th>\n",
       "      <th>fullname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>OOSUMETTOV MIXAN</td>\n",
       "      <td>OROSUMEBTOV MIRLAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>- </td>\n",
       "      <td>- </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>MUXATOV ELDOR</td>\n",
       "      <td>MURATOV ELDO.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>GULIYEV KHALID QABIL OGLU</td>\n",
       "      <td>GULIYEV KHALID QABI. OGLU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>ALIYEV XASAY SALMAN</td>\n",
       "      <td>ALIYEV XASAY SALMANJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>BADUCOVA ALLA GENNAEVNA</td>\n",
       "      <td>BADUROVA ALLA GENNAREVNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>ZHUSUPBEKOVA NUIA </td>\n",
       "      <td>ZHUSUPBEKOVA NURIA </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>KADIROV MEDETBEK</td>\n",
       "      <td>KADIDOV MEDETBEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767588</th>\n",
       "      <td>2767588</td>\n",
       "      <td>0</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767589</th>\n",
       "      <td>2767589</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767590</th>\n",
       "      <td>2767590</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767593</th>\n",
       "      <td>2767593</td>\n",
       "      <td>1</td>\n",
       "      <td>ABDYKALYKOV MILBEK</td>\n",
       "      <td>ABDYKALYKOV MIRBEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767595</th>\n",
       "      <td>2767595</td>\n",
       "      <td>2</td>\n",
       "      <td>TABACAI POITA</td>\n",
       "      <td>TABACARI POIOTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767596</th>\n",
       "      <td>2767596</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767599</th>\n",
       "      <td>2767599</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767600</th>\n",
       "      <td>2767600</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767603</th>\n",
       "      <td>2767603</td>\n",
       "      <td>1</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767604</th>\n",
       "      <td>2767604</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767605</th>\n",
       "      <td>2767605</td>\n",
       "      <td>1</td>\n",
       "      <td>ASHIDKHANOV NIZOMXON NABIVILLOLXON O'G'LI</td>\n",
       "      <td>RASHIDKHANOV NIZOMXON NABIVILLOLXON O'G'LI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767606</th>\n",
       "      <td>2767606</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767608</th>\n",
       "      <td>2767608</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767609</th>\n",
       "      <td>2767609</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767610</th>\n",
       "      <td>2767610</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767611</th>\n",
       "      <td>2767611</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767614</th>\n",
       "      <td>2767614</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767615</th>\n",
       "      <td>2767615</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767617</th>\n",
       "      <td>2767617</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767618</th>\n",
       "      <td>2767618</td>\n",
       "      <td>1</td>\n",
       "      <td>KISPENZ ALEX</td>\n",
       "      <td>KRISPENZ ALEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767619</th>\n",
       "      <td>2767619</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767621</th>\n",
       "      <td>2767621</td>\n",
       "      <td>1</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767622</th>\n",
       "      <td>2767622</td>\n",
       "      <td>1</td>\n",
       "      <td>   </td>\n",
       "      <td>   </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767623</th>\n",
       "      <td>2767623</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767625</th>\n",
       "      <td>2767625</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767629</th>\n",
       "      <td>2767629</td>\n",
       "      <td>1</td>\n",
       "      <td>KHUKJAMOV FAKHAD</td>\n",
       "      <td>KHUKJAMOV FARKHAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767630</th>\n",
       "      <td>2767630</td>\n",
       "      <td>1</td>\n",
       "      <td>   </td>\n",
       "      <td>   </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767631</th>\n",
       "      <td>2767631</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767637</th>\n",
       "      <td>2767637</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767638</th>\n",
       "      <td>2767638</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1649442 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  target                              fullname_true  \\\n",
       "0              0       1                   \n",
       "3              3       1                   \n",
       "4              4       1                          OOSUMETTOV MIXAN   \n",
       "5              5       2                 \n",
       "6              6       1                           \n",
       "7              7       1                    \n",
       "8              8       1                       \n",
       "9              9       1                \n",
       "10            10       1                    -    \n",
       "11            11       1                   \n",
       "13            13       1                              MUXATOV ELDOR   \n",
       "14            14       1                  GULIYEV KHALID QABIL OGLU   \n",
       "18            18       1                       \n",
       "21            21       1                        \n",
       "22            22       1                      \n",
       "23            23       1                   \n",
       "24            24       1                        ALIYEV XASAY SALMAN   \n",
       "25            25       1                        \n",
       "27            27       1                      \n",
       "28            28       1                        \n",
       "29            29       1                   \n",
       "31            31       1                          \n",
       "32            32       1                \n",
       "35            35       1                   BADUCOVA ALLA GENNAEVNA   \n",
       "37            37       1                  \n",
       "38            38       2                     ZHUSUPBEKOVA NUIA    \n",
       "40            40       1                           KADIROV MEDETBEK   \n",
       "41            41       1                      \n",
       "42            42       1                   \n",
       "44            44       1                                   \n",
       "...          ...     ...                                        ...   \n",
       "2767588  2767588       0                         \n",
       "2767589  2767589       1                  \n",
       "2767590  2767590       1                        \n",
       "2767593  2767593       1                         ABDYKALYKOV MILBEK   \n",
       "2767595  2767595       2                             TABACAI POITA   \n",
       "2767596  2767596       1                        \n",
       "2767599  2767599       1                    \n",
       "2767600  2767600       1                     \n",
       "2767603  2767603       1                                 \n",
       "2767604  2767604       1                 \n",
       "2767605  2767605       1  ASHIDKHANOV NIZOMXON NABIVILLOLXON O'G'LI   \n",
       "2767606  2767606       1                       \n",
       "2767608  2767608       1                  \n",
       "2767609  2767609       1                         \n",
       "2767610  2767610       1                 \n",
       "2767611  2767611       1                \n",
       "2767614  2767614       1                         \n",
       "2767615  2767615       1                   \n",
       "2767617  2767617       1                      \n",
       "2767618  2767618       1                              KISPENZ ALEX   \n",
       "2767619  2767619       1                 \n",
       "2767621  2767621       1                         \n",
       "2767622  2767622       1                        \n",
       "2767623  2767623       1                      \n",
       "2767625  2767625       1                         \n",
       "2767629  2767629       1                           KHUKJAMOV FAKHAD   \n",
       "2767630  2767630       1                       \n",
       "2767631  2767631       1                       \n",
       "2767637  2767637       1                    \n",
       "2767638  2767638       1                    \n",
       "\n",
       "                                           fullname  \n",
       "0                        \n",
       "3                         \n",
       "4                                OROSUMEBTOV MIRLAN  \n",
       "5                       \n",
       "6                                \n",
       "7                          \n",
       "8                             \n",
       "9                      \n",
       "10                          -   \n",
       "11                        \n",
       "13                                    MURATOV ELDO.  \n",
       "14                        GULIYEV KHALID QABI. OGLU  \n",
       "18                           \n",
       "21                            \n",
       "22                          \n",
       "23                        \n",
       "24                             ALIYEV XASAY SALMANJ  \n",
       "25                            \n",
       "27                          \n",
       "28                            \n",
       "29                       \n",
       "31                               \n",
       "32                    \n",
       "35                         BADUROVA ALLA GENNAREVNA  \n",
       "37                     \n",
       "38                           ZHUSUPBEKOVA NURIA   \n",
       "40                                 KADIDOV MEDETBEK  \n",
       "41                          \n",
       "42                        \n",
       "44                                       \n",
       "...                                             ...  \n",
       "2767588                        \n",
       "2767589                  \n",
       "2767590                        \n",
       "2767593                          ABDYKALYKOV MIRBEK  \n",
       "2767595                             TABACARI POIOTR  \n",
       "2767596                       \n",
       "2767599                    \n",
       "2767600                    \n",
       "2767603                                \n",
       "2767604                \n",
       "2767605  RASHIDKHANOV NIZOMXON NABIVILLOLXON O'G'LI  \n",
       "2767606                       \n",
       "2767608                 \n",
       "2767609                        \n",
       "2767610                 \n",
       "2767611               \n",
       "2767614                        \n",
       "2767615                   \n",
       "2767617                      \n",
       "2767618                               KRISPENZ ALEX  \n",
       "2767619                 \n",
       "2767621                         \n",
       "2767622                       \n",
       "2767623                      \n",
       "2767625                         \n",
       "2767629                           KHUKJAMOV FARKHAD  \n",
       "2767630                      \n",
       "2767631                       \n",
       "2767637                   \n",
       "2767638                   \n",
       "\n",
       "[1649442 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df[predict_df.fullname_true!=predict_df.fullname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T06:28:28.959883Z",
     "start_time": "2018-10-24T06:28:28.808749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>fullname_true</th>\n",
       "      <th>fullname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1186299</th>\n",
       "      <td>1186299</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594162</th>\n",
       "      <td>2594162</td>\n",
       "      <td>1</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974206</th>\n",
       "      <td>1974206</td>\n",
       "      <td>0</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617660</th>\n",
       "      <td>1617660</td>\n",
       "      <td>0</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820009</th>\n",
       "      <td>1820009</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737322</th>\n",
       "      <td>737322</td>\n",
       "      <td>0</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945034</th>\n",
       "      <td>945034</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557808</th>\n",
       "      <td>1557808</td>\n",
       "      <td>1</td>\n",
       "      <td>KARIMOV MAKHMADALI</td>\n",
       "      <td>KARIMOV MAKHMADALI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650347</th>\n",
       "      <td>1650347</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858065</th>\n",
       "      <td>858065</td>\n",
       "      <td>1</td>\n",
       "      <td>  </td>\n",
       "      <td>  </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  target                    fullname_true  \\\n",
       "1186299  1186299       1         \n",
       "2594162  2594162       1                     \n",
       "1974206  1974206       0           \n",
       "1617660  1617660       0              \n",
       "1820009  1820009       1              \n",
       "737322    737322       0       \n",
       "945034    945034       1          \n",
       "1557808  1557808       1               KARIMOV MAKHMADALI   \n",
       "1650347  1650347       1             \n",
       "858065    858065       1          \n",
       "\n",
       "                                fullname  \n",
       "1186299         \n",
       "2594162                    \n",
       "1974206          \n",
       "1617660             \n",
       "1820009            \n",
       "737322       \n",
       "945034         \n",
       "1557808               KARIMOV MAKHMADALI  \n",
       "1650347            \n",
       "858065           "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T09:38:07.183487Z",
     "start_time": "2018-10-27T09:38:07.017110Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T09:38:16.885980Z",
     "start_time": "2018-10-27T09:38:16.883668Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T09:38:17.492216Z",
     "start_time": "2018-10-27T09:38:17.488420Z"
    }
   },
   "outputs": [],
   "source": [
    "# your tensor of 16 x 28 dimensions, \n",
    "# where each element has some index (0 to n)\n",
    "inp = torch.LongTensor(16, 28) % n    \n",
    "inp_ = torch.unsqueeze(inp, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-27T09:38:22.602068Z",
     "start_time": "2018-10-27T09:38:22.599180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 28, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "one_hot = torch.FloatTensor(16, 28, n).zero_()\n",
    "one_hot.scatter_(2, inp_, 1)\n",
    "\n",
    "print(inp)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T06:18:00.017169Z",
     "start_time": "2018-10-24T06:17:59.732894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
